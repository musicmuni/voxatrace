"use strict";(globalThis.webpackChunkdocs=globalThis.webpackChunkdocs||[]).push([[8256],{2661(e,i,t){t.r(i),t.d(i,{assets:()=>c,contentTitle:()=>s,default:()=>h,frontMatter:()=>l,metadata:()=>n,toc:()=>o});const n=JSON.parse('{"id":"calibra/speaking-pitch","title":"CalibraSpeakingPitch","description":"Natural speaking pitch detection for voice profiling. Detects the median fundamental frequency of a person\'s voice when speaking naturally.","source":"@site/docs/calibra/speaking-pitch.md","sourceDirName":"calibra","slug":"/calibra/speaking-pitch","permalink":"/voxatrace/calibra/speaking-pitch","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":10,"frontMatter":{"sidebar_position":10},"sidebar":"docsSidebar","previous":{"title":"CalibraBreath","permalink":"/voxatrace/calibra/breath"},"next":{"title":"CalibraEffects","permalink":"/voxatrace/calibra/effects"}}');var r=t(4848),a=t(8453);const l={sidebar_position:10},s="CalibraSpeakingPitch",c={},o=[{value:"Quick Start",id:"quick-start",level:2},{value:"Kotlin",id:"kotlin",level:3},{value:"Swift",id:"swift",level:3},{value:"When to Use",id:"when-to-use",level:2},{value:"Methods",id:"methods",level:2},{value:"detectFromAudio",id:"detectfromaudio",level:3},{value:"Kotlin",id:"kotlin-1",level:4},{value:"Swift",id:"swift-1",level:4},{value:"Parameters",id:"parameters",level:4},{value:"Return Value",id:"return-value",level:4},{value:"Example",id:"example",level:4},{value:"detectFromPitch",id:"detectfrompitch",level:3},{value:"Kotlin",id:"kotlin-2",level:4},{value:"Swift",id:"swift-2",level:4},{value:"Parameters",id:"parameters-1",level:4},{value:"Return Value",id:"return-value-1",level:4},{value:"Example",id:"example-1",level:4},{value:"Typical Speaking Pitches",id:"typical-speaking-pitches",level:2},{value:"Common Patterns",id:"common-patterns",level:2},{value:"Voice Profile Setup",id:"voice-profile-setup",level:3},{value:"Reusing an Existing Pitch Contour",id:"reusing-an-existing-pitch-contour",level:3},{value:"Platform Notes",id:"platform-notes",level:2},{value:"Common Pitfalls",id:"common-pitfalls",level:2},{value:"Next Steps",id:"next-steps",level:2}];function d(e){const i={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,a.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(i.header,{children:(0,r.jsx)(i.h1,{id:"calibraspeakingpitch",children:"CalibraSpeakingPitch"})}),"\n",(0,r.jsx)(i.p,{children:"Natural speaking pitch detection for voice profiling. Detects the median fundamental frequency of a person's voice when speaking naturally."}),"\n",(0,r.jsx)(i.h2,{id:"quick-start",children:"Quick Start"}),"\n",(0,r.jsx)(i.h3,{id:"kotlin",children:"Kotlin"}),"\n",(0,r.jsx)(i.pre,{children:(0,r.jsx)(i.code,{className:"language-kotlin",children:'// From audio samples (16kHz mono)\r\nval speakingPitch = CalibraSpeakingPitch.detectFromAudio(audioSamples)\r\n\r\nif (speakingPitch > 0) {\r\n    println("Speaking pitch: $speakingPitch Hz")\r\n    val note = CalibraMusic.hzToNoteLabel(speakingPitch)\r\n    println("Closest note: $note")\r\n}\r\n\r\n// Or from existing pitch contour\r\nval contour = pitchExtractor.extract(audio, 16000)\r\nval speakingPitch = CalibraSpeakingPitch.detectFromPitch(contour.toPitchesArray())\n'})}),"\n",(0,r.jsx)(i.h3,{id:"swift",children:"Swift"}),"\n",(0,r.jsx)(i.pre,{children:(0,r.jsx)(i.code,{className:"language-swift",children:'// From audio samples (16kHz mono)\r\nlet speakingPitch = CalibraSpeakingPitch.detectFromAudio(audioMono: audioSamples)\r\n\r\nif speakingPitch > 0 {\r\n    print("Speaking pitch: \\(speakingPitch) Hz")\r\n    let note = CalibraMusic.hzToNoteLabel(speakingPitch)\r\n    print("Closest note: \\(note)")\r\n}\r\n\r\n// Or from existing pitch contour\r\nlet contour = pitchExtractor.extract(audio: audio, sampleRate: 16000)\r\nlet speakingPitch = CalibraSpeakingPitch.detectFromPitch(pitchesHz: contour.toPitchesArray())\n'})}),"\n",(0,r.jsx)(i.h2,{id:"when-to-use",children:"When to Use"}),"\n",(0,r.jsxs)(i.table,{children:[(0,r.jsx)(i.thead,{children:(0,r.jsxs)(i.tr,{children:[(0,r.jsx)(i.th,{children:"Scenario"}),(0,r.jsx)(i.th,{children:"Use This?"}),(0,r.jsx)(i.th,{children:"Why"})]})}),(0,r.jsxs)(i.tbody,{children:[(0,r.jsxs)(i.tr,{children:[(0,r.jsx)(i.td,{children:"Detect natural voice pitch"}),(0,r.jsx)(i.td,{children:"Yes"}),(0,r.jsx)(i.td,{children:"Core use case"})]}),(0,r.jsxs)(i.tr,{children:[(0,r.jsx)(i.td,{children:"Classify voice type"}),(0,r.jsx)(i.td,{children:"Yes"}),(0,r.jsx)(i.td,{children:"Based on frequency range"})]}),(0,r.jsxs)(i.tr,{children:[(0,r.jsx)(i.td,{children:"Suggest shruti/tonic"}),(0,r.jsx)(i.td,{children:"Yes"}),(0,r.jsx)(i.td,{children:"Recommend musical reference note"})]}),(0,r.jsxs)(i.tr,{children:[(0,r.jsx)(i.td,{children:"Voice health tracking"}),(0,r.jsx)(i.td,{children:"Yes"}),(0,r.jsx)(i.td,{children:"Monitor changes over time"})]}),(0,r.jsxs)(i.tr,{children:[(0,r.jsx)(i.td,{children:"Detect singing range"}),(0,r.jsx)(i.td,{children:"No"}),(0,r.jsxs)(i.td,{children:["Use ",(0,r.jsx)(i.code,{children:"CalibraVocalRange"})]})]}),(0,r.jsxs)(i.tr,{children:[(0,r.jsx)(i.td,{children:"Real-time pitch display"}),(0,r.jsx)(i.td,{children:"No"}),(0,r.jsxs)(i.td,{children:["Use ",(0,r.jsx)(i.code,{children:"CalibraPitch"})]})]})]})]}),"\n",(0,r.jsx)(i.h2,{id:"methods",children:"Methods"}),"\n",(0,r.jsx)(i.h3,{id:"detectfromaudio",children:"detectFromAudio"}),"\n",(0,r.jsx)(i.p,{children:"Detect natural speaking pitch from audio samples. Analyzes spoken audio to find the median fundamental frequency. Works best with natural speech samples. Automatically resamples to 16kHz internally if needed."}),"\n",(0,r.jsx)(i.h4,{id:"kotlin-1",children:"Kotlin"}),"\n",(0,r.jsx)(i.pre,{children:(0,r.jsx)(i.code,{className:"language-kotlin",children:"fun detectFromAudio(audioMono: FloatArray, sampleRate: Int = 16000): Float\n"})}),"\n",(0,r.jsx)(i.h4,{id:"swift-1",children:"Swift"}),"\n",(0,r.jsx)(i.pre,{children:(0,r.jsx)(i.code,{className:"language-swift",children:"static func detectFromAudio(audioMono: [Float], sampleRate: Int = 16000) -> Float\n"})}),"\n",(0,r.jsx)(i.h4,{id:"parameters",children:"Parameters"}),"\n",(0,r.jsxs)(i.table,{children:[(0,r.jsx)(i.thead,{children:(0,r.jsxs)(i.tr,{children:[(0,r.jsx)(i.th,{children:"Parameter"}),(0,r.jsx)(i.th,{children:"Type"}),(0,r.jsx)(i.th,{children:"Default"}),(0,r.jsx)(i.th,{children:"Description"})]})}),(0,r.jsxs)(i.tbody,{children:[(0,r.jsxs)(i.tr,{children:[(0,r.jsx)(i.td,{children:(0,r.jsx)(i.code,{children:"audioMono"})}),(0,r.jsxs)(i.td,{children:[(0,r.jsx)(i.code,{children:"FloatArray"})," / ",(0,r.jsx)(i.code,{children:"[Float]"})]}),(0,r.jsx)(i.td,{children:"--"}),(0,r.jsx)(i.td,{children:"Mono audio samples (normalized -1 to 1)"})]}),(0,r.jsxs)(i.tr,{children:[(0,r.jsx)(i.td,{children:(0,r.jsx)(i.code,{children:"sampleRate"})}),(0,r.jsx)(i.td,{children:(0,r.jsx)(i.code,{children:"Int"})}),(0,r.jsx)(i.td,{children:(0,r.jsx)(i.code,{children:"16000"})}),(0,r.jsx)(i.td,{children:"Sample rate of the input audio in Hz"})]})]})]}),"\n",(0,r.jsx)(i.h4,{id:"return-value",children:"Return Value"}),"\n",(0,r.jsxs)(i.p,{children:["Detected frequency in Hz, or ",(0,r.jsx)(i.code,{children:"-1"})," if detection failed (not enough voiced audio)."]}),"\n",(0,r.jsx)(i.h4,{id:"example",children:"Example"}),"\n",(0,r.jsx)(i.pre,{children:(0,r.jsx)(i.code,{className:"language-kotlin",children:'// Kotlin\r\nval audioData = SonixDecoder.decode("/path/to/speech.mp3")\r\nval samples16k = SonixResampler.resample(audioData.samples, audioData.sampleRate, 16000)\r\nval speakingPitch = CalibraSpeakingPitch.detectFromAudio(samples16k)\n'})}),"\n",(0,r.jsx)(i.pre,{children:(0,r.jsx)(i.code,{className:"language-swift",children:'// Swift\r\nlet audioData = SonixDecoder.decode(path: "/path/to/speech.mp3")!\r\nlet samples16k = SonixResampler.resample(samples: audioData.samples,\r\n                                         fromRate: Int(audioData.sampleRate),\r\n                                         toRate: 16000)\r\nlet speakingPitch = CalibraSpeakingPitch.detectFromAudio(audioMono: samples16k)\n'})}),"\n",(0,r.jsx)(i.h3,{id:"detectfrompitch",children:"detectFromPitch"}),"\n",(0,r.jsx)(i.p,{children:"Detect natural speaking pitch from an existing pitch contour. Analyzes pitch values to find the median pitch. Useful when you have already extracted pitches from audio."}),"\n",(0,r.jsx)(i.h4,{id:"kotlin-2",children:"Kotlin"}),"\n",(0,r.jsx)(i.pre,{children:(0,r.jsx)(i.code,{className:"language-kotlin",children:"fun detectFromPitch(pitchesHz: FloatArray): Float\n"})}),"\n",(0,r.jsx)(i.h4,{id:"swift-2",children:"Swift"}),"\n",(0,r.jsx)(i.pre,{children:(0,r.jsx)(i.code,{className:"language-swift",children:"static func detectFromPitch(pitchesHz: [Float]) -> Float\n"})}),"\n",(0,r.jsx)(i.h4,{id:"parameters-1",children:"Parameters"}),"\n",(0,r.jsxs)(i.table,{children:[(0,r.jsx)(i.thead,{children:(0,r.jsxs)(i.tr,{children:[(0,r.jsx)(i.th,{children:"Parameter"}),(0,r.jsx)(i.th,{children:"Type"}),(0,r.jsx)(i.th,{children:"Description"})]})}),(0,r.jsx)(i.tbody,{children:(0,r.jsxs)(i.tr,{children:[(0,r.jsx)(i.td,{children:(0,r.jsx)(i.code,{children:"pitchesHz"})}),(0,r.jsxs)(i.td,{children:[(0,r.jsx)(i.code,{children:"FloatArray"})," / ",(0,r.jsx)(i.code,{children:"[Float]"})]}),(0,r.jsx)(i.td,{children:"Pitch values in Hz (-1 for unvoiced frames)"})]})})]}),"\n",(0,r.jsx)(i.h4,{id:"return-value-1",children:"Return Value"}),"\n",(0,r.jsxs)(i.p,{children:["Detected frequency in Hz, or ",(0,r.jsx)(i.code,{children:"-1"})," if detection failed."]}),"\n",(0,r.jsx)(i.h4,{id:"example-1",children:"Example"}),"\n",(0,r.jsx)(i.pre,{children:(0,r.jsx)(i.code,{className:"language-kotlin",children:"// Kotlin\r\nval extractor = CalibraPitch.createContourExtractor()\r\nval contour = extractor.extract(audioSamples, sampleRate = 16000)\r\nval speakingPitch = CalibraSpeakingPitch.detectFromPitch(contour.toPitchesArray())\r\nextractor.release()\n"})}),"\n",(0,r.jsx)(i.pre,{children:(0,r.jsx)(i.code,{className:"language-swift",children:"// Swift\r\nlet extractor = CalibraPitch.createContourExtractor()\r\nlet contour = extractor.extract(audio: audioSamples, sampleRate: 16000)\r\nlet speakingPitch = CalibraSpeakingPitch.detectFromPitch(pitchesHz: contour.toPitchesArray())\r\nextractor.release()\n"})}),"\n",(0,r.jsx)(i.h2,{id:"typical-speaking-pitches",children:"Typical Speaking Pitches"}),"\n",(0,r.jsxs)(i.table,{children:[(0,r.jsx)(i.thead,{children:(0,r.jsxs)(i.tr,{children:[(0,r.jsx)(i.th,{children:"Voice Type"}),(0,r.jsx)(i.th,{children:"Typical Range"})]})}),(0,r.jsxs)(i.tbody,{children:[(0,r.jsxs)(i.tr,{children:[(0,r.jsx)(i.td,{children:"Bass"}),(0,r.jsx)(i.td,{children:"85--155 Hz"})]}),(0,r.jsxs)(i.tr,{children:[(0,r.jsx)(i.td,{children:"Baritone"}),(0,r.jsx)(i.td,{children:"110--165 Hz"})]}),(0,r.jsxs)(i.tr,{children:[(0,r.jsx)(i.td,{children:"Tenor"}),(0,r.jsx)(i.td,{children:"130--200 Hz"})]}),(0,r.jsxs)(i.tr,{children:[(0,r.jsx)(i.td,{children:"Alto"}),(0,r.jsx)(i.td,{children:"175--255 Hz"})]}),(0,r.jsxs)(i.tr,{children:[(0,r.jsx)(i.td,{children:"Soprano"}),(0,r.jsx)(i.td,{children:"220--330 Hz"})]})]})]}),"\n",(0,r.jsx)(i.h2,{id:"common-patterns",children:"Common Patterns"}),"\n",(0,r.jsx)(i.h3,{id:"voice-profile-setup",children:"Voice Profile Setup"}),"\n",(0,r.jsx)(i.pre,{children:(0,r.jsx)(i.code,{className:"language-kotlin",children:'class VoiceProfileViewModel : ViewModel() {\r\n    fun detectSpeakingPitch(audioPath: String) {\r\n        viewModelScope.launch {\r\n            val audioData = SonixDecoder.decode(audioPath) ?: return@launch\r\n            val samples16k = SonixResampler.resample(\r\n                audioData.samples, audioData.sampleRate, 16000\r\n            )\r\n\r\n            val pitchHz = CalibraSpeakingPitch.detectFromAudio(samples16k)\r\n            if (pitchHz > 0) {\r\n                val noteLabel = CalibraMusic.hzToNoteLabel(pitchHz)\r\n                println("Speaking pitch: $noteLabel ($pitchHz Hz)")\r\n            } else {\r\n                println("Could not detect speaking pitch")\r\n            }\r\n        }\r\n    }\r\n}\n'})}),"\n",(0,r.jsx)(i.h3,{id:"reusing-an-existing-pitch-contour",children:"Reusing an Existing Pitch Contour"}),"\n",(0,r.jsx)(i.p,{children:"If you have already extracted a pitch contour (e.g., for visualization or scoring), you can pass it directly to avoid re-processing the audio:"}),"\n",(0,r.jsx)(i.pre,{children:(0,r.jsx)(i.code,{className:"language-kotlin",children:"val extractor = CalibraPitch.createContourExtractor()\r\nval contour = extractor.extract(audioSamples, sampleRate = 16000)\r\n\r\n// Use contour for visualization...\r\nupdatePitchDisplay(contour)\r\n\r\n// Also derive speaking pitch from the same contour\r\nval speakingPitch = CalibraSpeakingPitch.detectFromPitch(contour.toPitchesArray())\r\nextractor.release()\n"})}),"\n",(0,r.jsx)(i.h2,{id:"platform-notes",children:"Platform Notes"}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"iOS/Android"}),": Accepts any sample rate; internally resamples to 16kHz if needed."]}),"\n",(0,r.jsx)(i.li,{children:"Uses median-based detection in MIDI space for robustness against outliers."}),"\n",(0,r.jsxs)(i.li,{children:["Returns ",(0,r.jsx)(i.code,{children:"-1"})," if detection fails (not enough voiced audio)."]}),"\n",(0,r.jsx)(i.li,{children:"Requires several seconds of natural speech for reliable results."}),"\n"]}),"\n",(0,r.jsx)(i.h2,{id:"common-pitfalls",children:"Common Pitfalls"}),"\n",(0,r.jsxs)(i.ol,{children:["\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Singing instead of speaking"})," -- This detects speaking pitch, not singing range. For singing, use ",(0,r.jsx)(i.code,{children:"CalibraVocalRange"}),"."]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Not enough audio"})," -- Short clips may not contain enough voiced frames. Aim for several seconds of natural speech."]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Background noise"})," -- High noise levels can affect detection accuracy. Record in a reasonably quiet environment."]}),"\n"]}),"\n",(0,r.jsx)(i.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.a,{href:"./vocal-range",children:"CalibraVocalRange"})," -- Detect full singing range"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.a,{href:"./pitch",children:"CalibraPitch"})," -- Real-time pitch detection"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.a,{href:"./vad",children:"CalibraVAD"})," -- Voice activity detection"]}),"\n"]})]})}function h(e={}){const{wrapper:i}={...(0,a.R)(),...e.components};return i?(0,r.jsx)(i,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},8453(e,i,t){t.d(i,{R:()=>l,x:()=>s});var n=t(6540);const r={},a=n.createContext(r);function l(e){const i=n.useContext(a);return n.useMemo(function(){return"function"==typeof e?e(i):{...i,...e}},[i,e])}function s(e){let i;return i=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:l(e.components),n.createElement(a.Provider,{value:i},e.children)}}}]);