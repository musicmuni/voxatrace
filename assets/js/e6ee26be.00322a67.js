"use strict";(globalThis.webpackChunkdocs=globalThis.webpackChunkdocs||[]).push([[87627],{28453(e,i,a){a.d(i,{R:()=>t,x:()=>l});var r=a(96540);const n={},c=r.createContext(n);function t(e){const i=r.useContext(c);return r.useMemo(function(){return"function"==typeof e?e(i):{...i,...e}},[i,e])}function l(e){let i;return i=e.disableParentContext?"function"==typeof e.components?e.components(n):e.components||n:t(e.components),r.createElement(c.Provider,{value:i},e.children)}},90406(e,i,a){a.r(i),a.d(i,{assets:()=>s,contentTitle:()=>l,default:()=>h,frontMatter:()=>t,metadata:()=>r,toc:()=>o});const r=JSON.parse('{"id":"api/voxatrace/com.musicmuni.voxatrace.calibra/-calibra-v-a-d/index","title":"index","description":"//voxatrace/com.musicmuni.voxatrace.calibra/CalibraVAD","source":"@site/docs/api/voxatrace/com.musicmuni.voxatrace.calibra/-calibra-v-a-d/index.md","sourceDirName":"api/voxatrace/com.musicmuni.voxatrace.calibra/-calibra-v-a-d","slug":"/api/voxatrace/com.musicmuni.voxatrace.calibra/-calibra-v-a-d/","permalink":"/voxatrace/docs/api/voxatrace/com.musicmuni.voxatrace.calibra/-calibra-v-a-d/","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"apiSidebar","previous":{"title":"detect-from-pitch","permalink":"/voxatrace/docs/api/voxatrace/com.musicmuni.voxatrace.calibra/-calibra-speaking-pitch/detect-from-pitch"},"next":{"title":"index","permalink":"/voxatrace/docs/api/voxatrace/com.musicmuni.voxatrace.calibra/-calibra-v-a-d/-companion/"}}');var n=a(74848),c=a(28453);const t={},l="CalibraVAD",s={},o=[{value:"What is VAD?",id:"what-is-vad",level:2},{value:"When to Use",id:"when-to-use",level:2},{value:"Quick Start",id:"quick-start",level:2},{value:"Kotlin",id:"kotlin",level:3},{value:"Swift",id:"swift",level:3},{value:"Usage Tiers (ADR-001)",id:"usage-tiers-adr-001",level:2},{value:"Tier 1: Simple Creation (80% of users)",id:"tier-1-simple-creation-80-of-users",level:3},{value:"Kotlin",id:"kotlin-1",level:4},{value:"Swift",id:"swift-1",level:4},{value:"Tier 2: Custom Config (15% of users)",id:"tier-2-custom-config-15-of-users",level:3},{value:"Kotlin",id:"kotlin-2",level:4},{value:"Swift",id:"swift-2",level:4},{value:"Streaming Mode",id:"streaming-mode",level:2},{value:"Kotlin",id:"kotlin-3",level:3},{value:"Swift",id:"swift-3",level:3},{value:"Platform Notes",id:"platform-notes",level:2},{value:"iOS",id:"ios",level:3},{value:"Android",id:"android",level:3},{value:"Common Pitfalls",id:"common-pitfalls",level:2},{value:"See also",id:"see-also",level:4},{value:"Types",id:"types",level:2},{value:"Functions",id:"functions",level:2}];function d(e){const i={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,c.R)(),...e.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsxs)(i.p,{children:["//",(0,n.jsx)(i.a,{href:"/voxatrace/docs/api/",children:"voxatrace"}),"/",(0,n.jsx)(i.a,{href:"/voxatrace/docs/api/voxatrace/com.musicmuni.voxatrace.calibra/",children:"com.musicmuni.voxatrace.calibra"}),"/",(0,n.jsx)(i.a,{href:"/voxatrace/docs/api/voxatrace/com.musicmuni.voxatrace.calibra/-calibra-v-a-d/",children:"CalibraVAD"})]}),"\n",(0,n.jsx)(i.header,{children:(0,n.jsx)(i.h1,{id:"calibravad",children:"CalibraVAD"})}),"\n",(0,n.jsxs)(i.p,{children:["class ",(0,n.jsx)(i.a,{href:"/voxatrace/docs/api/voxatrace/com.musicmuni.voxatrace.calibra/-calibra-v-a-d/",children:"CalibraVAD"})]}),"\n",(0,n.jsx)(i.p,{children:"Voice Activity Detection (VAD) for identifying speech/singing in audio."}),"\n",(0,n.jsx)(i.h2,{id:"what-is-vad",children:"What is VAD?"}),"\n",(0,n.jsxs)(i.p,{children:["Voice Activity Detection determines ",(0,n.jsx)(i.strong,{children:"when someone is speaking or singing"})," vs. when there's silence or background noise. Use it for:"]}),"\n",(0,n.jsxs)(i.ul,{children:["\n",(0,n.jsxs)(i.li,{children:[(0,n.jsx)(i.strong,{children:"Recording apps"}),": Auto-start/stop recording when voice is detected"]}),"\n",(0,n.jsxs)(i.li,{children:[(0,n.jsx)(i.strong,{children:"Transcription"}),": Skip silent sections to save processing"]}),"\n",(0,n.jsxs)(i.li,{children:[(0,n.jsx)(i.strong,{children:"Singing evaluation"}),": Only score segments where the user is actually singing"]}),"\n",(0,n.jsxs)(i.li,{children:[(0,n.jsx)(i.strong,{children:"Noise gate control"}),": Mute audio when no voice is present"]}),"\n"]}),"\n",(0,n.jsx)(i.h2,{id:"when-to-use",children:"When to Use"}),"\n",(0,n.jsxs)(i.table,{children:[(0,n.jsx)(i.thead,{children:(0,n.jsxs)(i.tr,{children:[(0,n.jsx)(i.th,{children:"Scenario"}),(0,n.jsx)(i.th,{children:"Backend"}),(0,n.jsx)(i.th,{children:"Why"})]})}),(0,n.jsxs)(i.tbody,{children:[(0,n.jsxs)(i.tr,{children:[(0,n.jsx)(i.td,{children:"Simple voice detection"}),(0,n.jsx)(i.td,{children:(0,n.jsx)(i.code,{children:"General"})}),(0,n.jsx)(i.td,{children:"Fast, no model required"})]}),(0,n.jsxs)(i.tr,{children:[(0,n.jsx)(i.td,{children:"Accurate speech detection"}),(0,n.jsx)(i.td,{children:(0,n.jsx)(i.code,{children:"Speech"})}),(0,n.jsx)(i.td,{children:"Silero neural network, best for speech"})]}),(0,n.jsxs)(i.tr,{children:[(0,n.jsx)(i.td,{children:"Singing detection"}),(0,n.jsx)(i.td,{children:(0,n.jsx)(i.code,{children:"Singing"})}),(0,n.jsx)(i.td,{children:"YAMNet-based, distinguishes singing from speech"})]}),(0,n.jsxs)(i.tr,{children:[(0,n.jsx)(i.td,{children:"Low-latency singing"}),(0,n.jsx)(i.td,{children:(0,n.jsx)(i.code,{children:"SingingRealtime"})}),(0,n.jsx)(i.td,{children:"SwiftF0-based, minimal delay"})]})]})]}),"\n",(0,n.jsx)(i.h2,{id:"quick-start",children:"Quick Start"}),"\n",(0,n.jsx)(i.h3,{id:"kotlin",children:"Kotlin"}),"\n",(0,n.jsx)(i.pre,{children:(0,n.jsx)(i.code,{className:"language-kotlin",children:'// Simple energy-based detection (no model required)\nval vad = CalibraVAD.create(VADModelProvider.General)\nval ratio = vad.getVADRatio(samples, sampleRate = 48000)  // 0.0 to 1.0\nif (ratio 0.5f) {\n    println("Voice detected!")\n}\nvad.release()\n'})}),"\n",(0,n.jsx)(i.h3,{id:"swift",children:"Swift"}),"\n",(0,n.jsx)(i.pre,{children:(0,n.jsx)(i.code,{className:"language-swift",children:'// Simple energy-based detection (no model required)\nlet vad = CalibraVAD.companion.create(modelProvider: VADModelProvider.General())\nlet ratio = vad.getVADRatio(samples: samples, sampleRate: 48000)\nif ratio 0.5 {\n    print("Voice detected!")\n}\nvad.release()\n'})}),"\n",(0,n.jsx)(i.h2,{id:"usage-tiers-adr-001",children:"Usage Tiers (ADR-001)"}),"\n",(0,n.jsx)(i.h3,{id:"tier-1-simple-creation-80-of-users",children:"Tier 1: Simple Creation (80% of users)"}),"\n",(0,n.jsx)(i.h4,{id:"kotlin-1",children:"Kotlin"}),"\n",(0,n.jsx)(i.pre,{children:(0,n.jsx)(i.code,{className:"language-kotlin",children:"// GENERAL backend (no model required)\nval vad = CalibraVAD.create(VADModelProvider.General)\n\n// SPEECH backend (Silero model)\nval vad = CalibraVAD.create(VADModelProvider.Speech { ModelLoader.loadSpeechVAD() })\n"})}),"\n",(0,n.jsx)(i.h4,{id:"swift-1",children:"Swift"}),"\n",(0,n.jsx)(i.pre,{children:(0,n.jsx)(i.code,{className:"language-swift",children:"// GENERAL backend (no model required)\nlet vad = CalibraVAD.companion.create(modelProvider: VADModelProvider.General())\n\n// SPEECH backend (Silero model)\nlet vad = CalibraVAD.companion.create(\n    modelProvider: VADModelProvider.Speech { ModelLoader.shared.loadSpeechVAD() }\n)\n"})}),"\n",(0,n.jsx)(i.h3,{id:"tier-2-custom-config-15-of-users",children:"Tier 2: Custom Config (15% of users)"}),"\n",(0,n.jsx)(i.h4,{id:"kotlin-2",children:"Kotlin"}),"\n",(0,n.jsx)(i.pre,{children:(0,n.jsx)(i.code,{className:"language-kotlin",children:"val config = VADConfig.Builder()\n    .preset(VADConfig.SPEECH)\n    .threshold(0.4f)\n    .build()\nval vad = CalibraVAD.create(config, VADModelProvider.Speech { ModelLoader.loadSpeechVAD() })\n"})}),"\n",(0,n.jsx)(i.h4,{id:"swift-2",children:"Swift"}),"\n",(0,n.jsx)(i.pre,{children:(0,n.jsx)(i.code,{className:"language-swift",children:"let config = VADConfig.Builder()\n    .preset(config: VADConfig.companion.SPEECH)\n    .threshold(threshold: 0.4)\n    .build()\nlet vad = CalibraVAD.companion.create(\n    config: config,\n    modelProvider: VADModelProvider.Speech { ModelLoader.shared.loadSpeechVAD() }\n)\n"})}),"\n",(0,n.jsx)(i.h2,{id:"streaming-mode",children:"Streaming Mode"}),"\n",(0,n.jsx)(i.p,{children:"For real-time processing, use streaming mode:"}),"\n",(0,n.jsx)(i.h3,{id:"kotlin-3",children:"Kotlin"}),"\n",(0,n.jsx)(i.pre,{children:(0,n.jsx)(i.code,{className:"language-kotlin",children:"recorder.audioBuffers.collect { buffer ->\n    vad.acceptWaveform(buffer.toFloatArray(), sampleRate = 48000)\n    if (vad.isVoiceDetected()) {\n        showVoiceIndicator()\n    }\n}\n"})}),"\n",(0,n.jsx)(i.h3,{id:"swift-3",children:"Swift"}),"\n",(0,n.jsx)(i.pre,{children:(0,n.jsx)(i.code,{className:"language-swift",children:"for await buffer in recorder.audioBuffers {\n    vad.acceptWaveform(samples: buffer.toFloatArray(), sampleRate: 48000)\n    if vad.isVoiceDetected() {\n        showVoiceIndicator()\n    }\n}\n"})}),"\n",(0,n.jsx)(i.h2,{id:"platform-notes",children:"Platform Notes"}),"\n",(0,n.jsx)(i.h3,{id:"ios",children:"iOS"}),"\n",(0,n.jsxs)(i.ul,{children:["\n",(0,n.jsx)(i.li,{children:"Audio from microphone is typically 48kHz; resampled internally to 16kHz"}),"\n",(0,n.jsx)(i.li,{children:"Neural network backends (Speech, Singing) require ONNX Runtime"}),"\n",(0,n.jsx)(i.li,{children:"General backend works without any external dependencies"}),"\n"]}),"\n",(0,n.jsx)(i.h3,{id:"android",children:"Android"}),"\n",(0,n.jsxs)(i.ul,{children:["\n",(0,n.jsx)(i.li,{children:"Audio from microphone varies by device (44.1kHz, 48kHz, 16kHz)"}),"\n",(0,n.jsx)(i.li,{children:"Neural network backends use ONNX Runtime for Android"}),"\n",(0,n.jsx)(i.li,{children:"General backend is pure Kotlin, no native dependencies"}),"\n"]}),"\n",(0,n.jsx)(i.h2,{id:"common-pitfalls",children:"Common Pitfalls"}),"\n",(0,n.jsxs)(i.ol,{children:["\n",(0,n.jsxs)(i.li,{children:[(0,n.jsx)(i.strong,{children:"Forgetting to release"}),": Call ",(0,n.jsx)(i.code,{children:"vad.release()"})," to free native resources"]}),"\n",(0,n.jsxs)(i.li,{children:[(0,n.jsx)(i.strong,{children:"Using Speech backend for singing"}),": Speech VAD is trained on speech, not singing"]}),"\n",(0,n.jsxs)(i.li,{children:[(0,n.jsx)(i.strong,{children:"Too sensitive threshold"}),": Default thresholds work well; lower values = more false positives"]}),"\n",(0,n.jsxs)(i.li,{children:[(0,n.jsx)(i.strong,{children:"Not resetting between streams"}),": Call ",(0,n.jsx)(i.code,{children:"vad.reset()"})," when starting a new audio source"]}),"\n"]}),"\n",(0,n.jsx)(i.h4,{id:"see-also",children:"See also"}),"\n",(0,n.jsxs)(i.table,{children:[(0,n.jsx)(i.thead,{children:(0,n.jsxs)(i.tr,{children:[(0,n.jsx)(i.th,{}),(0,n.jsx)(i.th,{})]})}),(0,n.jsxs)(i.tbody,{children:[(0,n.jsxs)(i.tr,{children:[(0,n.jsx)(i.td,{children:(0,n.jsx)(i.a,{href:"/voxatrace/docs/api/voxatrace/com.musicmuni.voxatrace.calibra/-calibra-pitch/",children:"CalibraPitch"})}),(0,n.jsx)(i.td,{children:"For pitch detection (what note, not just voice presence)"})]}),(0,n.jsxs)(i.tr,{children:[(0,n.jsx)(i.td,{children:(0,n.jsx)(i.a,{href:"/voxatrace/docs/api/voxatrace/com.musicmuni.voxatrace.calibra/-calibra-live-eval/",children:"CalibraLiveEval"})}),(0,n.jsx)(i.td,{children:"For live singing evaluation (uses VAD internally)"})]}),(0,n.jsxs)(i.tr,{children:[(0,n.jsx)(i.td,{children:(0,n.jsx)(i.a,{href:"/voxatrace/docs/api/voxatrace/com.musicmuni.voxatrace.calibra.model/-v-a-d-config/",children:"VADConfig"})}),(0,n.jsx)(i.td,{children:"Configuration options for sensitivity tuning"})]}),(0,n.jsxs)(i.tr,{children:[(0,n.jsx)(i.td,{children:(0,n.jsx)(i.a,{href:"/voxatrace/docs/api/voxatrace/com.musicmuni.voxatrace.calibra.model/-v-a-d-model-provider/",children:"VADModelProvider"})}),(0,n.jsx)(i.td,{children:"Type-safe model provider selection"})]})]})]}),"\n",(0,n.jsx)(i.h2,{id:"types",children:"Types"}),"\n",(0,n.jsxs)(i.table,{children:[(0,n.jsx)(i.thead,{children:(0,n.jsxs)(i.tr,{children:[(0,n.jsx)(i.th,{children:"Name"}),(0,n.jsx)(i.th,{children:"Summary"})]})}),(0,n.jsx)(i.tbody,{children:(0,n.jsxs)(i.tr,{children:[(0,n.jsx)(i.td,{children:(0,n.jsx)(i.a,{href:"/voxatrace/docs/api/voxatrace/com.musicmuni.voxatrace.calibra/-calibra-v-a-d/-companion/",children:"Companion"})}),(0,n.jsxs)(i.td,{children:["[common]",(0,n.jsx)("br",{}),"object ",(0,n.jsx)(i.a,{href:"/voxatrace/docs/api/voxatrace/com.musicmuni.voxatrace.calibra/-calibra-v-a-d/-companion/",children:"Companion"})]})]})})]}),"\n",(0,n.jsx)(i.h2,{id:"functions",children:"Functions"}),"\n",(0,n.jsxs)(i.table,{children:[(0,n.jsx)(i.thead,{children:(0,n.jsxs)(i.tr,{children:[(0,n.jsx)(i.th,{children:"Name"}),(0,n.jsx)(i.th,{children:"Summary"})]})}),(0,n.jsxs)(i.tbody,{children:[(0,n.jsxs)(i.tr,{children:[(0,n.jsx)(i.td,{children:(0,n.jsx)(i.a,{href:"/voxatrace/docs/api/voxatrace/com.musicmuni.voxatrace.calibra/-calibra-v-a-d/accept-waveform",children:"acceptWaveform"})}),(0,n.jsxs)(i.td,{children:["[common]",(0,n.jsx)("br",{}),"fun ",(0,n.jsx)(i.a,{href:"/voxatrace/docs/api/voxatrace/com.musicmuni.voxatrace.calibra/-calibra-v-a-d/accept-waveform",children:"acceptWaveform"}),"(samples: ",(0,n.jsx)(i.a,{href:"https://kotlinlang.org/api/latest/jvm/stdlib/kotlin-stdlib/kotlin/-float-array/index.html",children:"FloatArray"}),", sampleRate: ",(0,n.jsx)(i.a,{href:"https://kotlinlang.org/api/latest/jvm/stdlib/kotlin-stdlib/kotlin/-int/index.html",children:"Int"})," = 16000)",(0,n.jsx)("br",{}),"Feed audio samples for streaming detection. Use with isSpeechDetected for real-time detection."]})]}),(0,n.jsxs)(i.tr,{children:[(0,n.jsx)(i.td,{children:(0,n.jsx)(i.a,{href:"/voxatrace/docs/api/voxatrace/com.musicmuni.voxatrace.calibra/-calibra-v-a-d/analyze",children:"analyze"})}),(0,n.jsxs)(i.td,{children:["[common]",(0,n.jsx)("br",{}),"fun ",(0,n.jsx)(i.a,{href:"/voxatrace/docs/api/voxatrace/com.musicmuni.voxatrace.calibra/-calibra-v-a-d/analyze",children:"analyze"}),"(samples: ",(0,n.jsx)(i.a,{href:"https://kotlinlang.org/api/latest/jvm/stdlib/kotlin-stdlib/kotlin/-float-array/index.html",children:"FloatArray"}),", sampleRate: ",(0,n.jsx)(i.a,{href:"https://kotlinlang.org/api/latest/jvm/stdlib/kotlin-stdlib/kotlin/-int/index.html",children:"Int"})," = 16000): ",(0,n.jsx)(i.a,{href:"/voxatrace/docs/api/voxatrace/com.musicmuni.voxatrace.calibra.model/-v-a-d-result/",children:"VADResult"}),"?",(0,n.jsx)("br",{}),"Analyze audio and return rich VAD result."]})]}),(0,n.jsxs)(i.tr,{children:[(0,n.jsx)(i.td,{children:(0,n.jsx)(i.a,{href:"/voxatrace/docs/api/voxatrace/com.musicmuni.voxatrace.calibra/-calibra-v-a-d/get-v-a-d-ratio",children:"getVADRatio"})}),(0,n.jsxs)(i.td,{children:["[common]",(0,n.jsx)("br",{}),"fun ",(0,n.jsx)(i.a,{href:"/voxatrace/docs/api/voxatrace/com.musicmuni.voxatrace.calibra/-calibra-v-a-d/get-v-a-d-ratio",children:"getVADRatio"}),"(samples: ",(0,n.jsx)(i.a,{href:"https://kotlinlang.org/api/latest/jvm/stdlib/kotlin-stdlib/kotlin/-float-array/index.html",children:"FloatArray"}),", sampleRate: ",(0,n.jsx)(i.a,{href:"https://kotlinlang.org/api/latest/jvm/stdlib/kotlin-stdlib/kotlin/-int/index.html",children:"Int"})," = 16000): ",(0,n.jsx)(i.a,{href:"https://kotlinlang.org/api/latest/jvm/stdlib/kotlin-stdlib/kotlin/-float/index.html",children:"Float"}),(0,n.jsx)("br",{}),"Get ratio of voiced frames in audio (0.0 to 1.0). Higher values indicate more speech/singing content."]})]}),(0,n.jsxs)(i.tr,{children:[(0,n.jsx)(i.td,{children:(0,n.jsx)(i.a,{href:"/voxatrace/docs/api/voxatrace/com.musicmuni.voxatrace.calibra/-calibra-v-a-d/is-voice-detected",children:"isVoiceDetected"})}),(0,n.jsxs)(i.td,{children:["[common]",(0,n.jsx)("br",{}),"fun ",(0,n.jsx)(i.a,{href:"/voxatrace/docs/api/voxatrace/com.musicmuni.voxatrace.calibra/-calibra-v-a-d/is-voice-detected",children:"isVoiceDetected"}),"(): ",(0,n.jsx)(i.a,{href:"https://kotlinlang.org/api/latest/jvm/stdlib/kotlin-stdlib/kotlin/-boolean/index.html",children:"Boolean"}),(0,n.jsx)("br",{}),"Check if voice is currently detected. Call after ",(0,n.jsx)(i.a,{href:"/voxatrace/docs/api/voxatrace/com.musicmuni.voxatrace.calibra/-calibra-v-a-d/accept-waveform",children:"acceptWaveform"})," for streaming mode."]})]}),(0,n.jsxs)(i.tr,{children:[(0,n.jsx)(i.td,{children:(0,n.jsx)(i.a,{href:"/voxatrace/docs/api/voxatrace/com.musicmuni.voxatrace.calibra/-calibra-v-a-d/release",children:"release"})}),(0,n.jsxs)(i.td,{children:["[common]",(0,n.jsx)("br",{}),"fun ",(0,n.jsx)(i.a,{href:"/voxatrace/docs/api/voxatrace/com.musicmuni.voxatrace.calibra/-calibra-v-a-d/release",children:"release"}),"()",(0,n.jsx)("br",{}),"Release all resources. Must be called when done to free native resources."]})]}),(0,n.jsxs)(i.tr,{children:[(0,n.jsx)(i.td,{children:(0,n.jsx)(i.a,{href:"/voxatrace/docs/api/voxatrace/com.musicmuni.voxatrace.calibra/-calibra-v-a-d/reset",children:"reset"})}),(0,n.jsxs)(i.td,{children:["[common]",(0,n.jsx)("br",{}),"fun ",(0,n.jsx)(i.a,{href:"/voxatrace/docs/api/voxatrace/com.musicmuni.voxatrace.calibra/-calibra-v-a-d/reset",children:"reset"}),"()",(0,n.jsx)("br",{}),"Reset VAD state for new audio stream. Call when starting to process a new audio source."]})]})]})]})]})}function h(e={}){const{wrapper:i}={...(0,c.R)(),...e.components};return i?(0,n.jsx)(i,{...e,children:(0,n.jsx)(d,{...e})}):d(e)}}}]);