"use strict";(globalThis.webpackChunkdocs=globalThis.webpackChunkdocs||[]).push([[3495],{7350(e,i,d){d.r(i),d.d(i,{assets:()=>t,contentTitle:()=>c,default:()=>o,frontMatter:()=>s,metadata:()=>r,toc:()=>a});const r=JSON.parse('{"id":"calibra/vad","title":"CalibraVAD","description":"Voice Activity Detection (VAD) for identifying speech and singing in audio. Determines when someone is speaking or singing vs. when there\'s silence or background noise.","source":"@site/docs/calibra/vad.md","sourceDirName":"calibra","slug":"/calibra/vad","permalink":"/calibra/vad","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3},"sidebar":"docsSidebar","previous":{"title":"CalibraPitch","permalink":"/calibra/pitch"},"next":{"title":"CalibraVocalRange","permalink":"/calibra/vocal-range"}}');var n=d(4848),l=d(8453);const s={sidebar_position:3},c="CalibraVAD",t={},a=[{value:"Quick Start",id:"quick-start",level:2},{value:"Kotlin",id:"kotlin",level:3},{value:"Swift",id:"swift",level:3},{value:"Backends",id:"backends",level:2},{value:"Creating a VAD",id:"creating-a-vad",level:2},{value:"With Model Provider Only (recommended)",id:"with-model-provider-only-recommended",level:3},{value:"With Custom Model Provider",id:"with-custom-model-provider",level:3},{value:"With Config + Model Provider",id:"with-config--model-provider",level:3},{value:"Configuration",id:"configuration",level:2},{value:"Presets",id:"presets",level:3},{value:"Config Properties",id:"config-properties",level:3},{value:"Builder Methods",id:"builder-methods",level:3},{value:"One-Shot Analysis",id:"one-shot-analysis",level:2},{value:"getVADRatio",id:"getvadratio",level:3},{value:"analyze",id:"analyze",level:3},{value:"VADResult",id:"vadresult",level:3},{value:"Streaming Mode",id:"streaming-mode",level:2},{value:"Kotlin",id:"kotlin-1",level:3},{value:"Swift",id:"swift-1",level:3},{value:"Swift Convenience Methods",id:"swift-convenience-methods",level:3},{value:"Methods",id:"methods",level:2},{value:"Common Patterns",id:"common-patterns",level:2},{value:"VAD with Recording",id:"vad-with-recording",level:3},{value:"Next Steps",id:"next-steps",level:2}];function h(e){const i={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,l.R)(),...e.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(i.header,{children:(0,n.jsx)(i.h1,{id:"calibravad",children:"CalibraVAD"})}),"\n",(0,n.jsx)(i.p,{children:"Voice Activity Detection (VAD) for identifying speech and singing in audio. Determines when someone is speaking or singing vs. when there's silence or background noise."}),"\n",(0,n.jsx)(i.h2,{id:"quick-start",children:"Quick Start"}),"\n",(0,n.jsx)(i.h3,{id:"kotlin",children:"Kotlin"}),"\n",(0,n.jsx)(i.pre,{children:(0,n.jsx)(i.code,{className:"language-kotlin",children:'val vad = CalibraVAD.create(VADModelProvider.General)\r\nval ratio = vad.getVADRatio(samples, sampleRate = 48000)\r\nif (ratio > 0.5f) {\r\n    println("Voice detected!")\r\n}\r\nvad.release()\n'})}),"\n",(0,n.jsx)(i.h3,{id:"swift",children:"Swift"}),"\n",(0,n.jsx)(i.pre,{children:(0,n.jsx)(i.code,{className:"language-swift",children:'let vad = CalibraVAD.create(.general)\r\nlet ratio = vad.getVADRatio(samples: samples, sampleRate: 48000)\r\nif ratio > 0.5 {\r\n    print("Voice detected!")\r\n}\r\nvad.release()\n'})}),"\n",(0,n.jsx)(i.h2,{id:"backends",children:"Backends"}),"\n",(0,n.jsxs)(i.table,{children:[(0,n.jsx)(i.thead,{children:(0,n.jsxs)(i.tr,{children:[(0,n.jsx)(i.th,{children:"Backend"}),(0,n.jsx)(i.th,{children:"Kotlin Provider"}),(0,n.jsx)(i.th,{children:"Swift Provider"}),(0,n.jsx)(i.th,{children:"Best For"}),(0,n.jsx)(i.th,{children:"Dependencies"})]})}),(0,n.jsxs)(i.tbody,{children:[(0,n.jsxs)(i.tr,{children:[(0,n.jsx)(i.td,{children:"General"}),(0,n.jsx)(i.td,{children:(0,n.jsx)(i.code,{children:"VADModelProvider.General"})}),(0,n.jsx)(i.td,{children:(0,n.jsx)(i.code,{children:".general"})}),(0,n.jsx)(i.td,{children:"Simple detection, low power"}),(0,n.jsx)(i.td,{children:"None"})]}),(0,n.jsxs)(i.tr,{children:[(0,n.jsx)(i.td,{children:"Speech"}),(0,n.jsx)(i.td,{children:(0,n.jsx)(i.code,{children:"VADModelProvider.speech()"})}),(0,n.jsx)(i.td,{children:(0,n.jsx)(i.code,{children:".speech()"})}),(0,n.jsx)(i.td,{children:"Speech detection"}),(0,n.jsx)(i.td,{children:"Silero ONNX"})]}),(0,n.jsxs)(i.tr,{children:[(0,n.jsx)(i.td,{children:"SingingRealtime"}),(0,n.jsx)(i.td,{children:(0,n.jsx)(i.code,{children:"VADModelProvider.singingRealtime()"})}),(0,n.jsx)(i.td,{children:(0,n.jsx)(i.code,{children:".singingRealtime()"})}),(0,n.jsx)(i.td,{children:"Low-latency singing"}),(0,n.jsx)(i.td,{children:"SwiftF0 ONNX"})]})]})]}),"\n",(0,n.jsx)(i.h2,{id:"creating-a-vad",children:"Creating a VAD"}),"\n",(0,n.jsx)(i.h3,{id:"with-model-provider-only-recommended",children:"With Model Provider Only (recommended)"}),"\n",(0,n.jsx)(i.p,{children:"Backend and defaults are inferred from the provider type:"}),"\n",(0,n.jsx)(i.pre,{children:(0,n.jsx)(i.code,{className:"language-kotlin",children:"// General (no model required)\r\nval vad = CalibraVAD.create(VADModelProvider.General)\r\n\r\n// Speech (Silero model)\r\nval vad = CalibraVAD.create(VADModelProvider.speech())\r\n\r\n// Singing realtime (SwiftF0 model)\r\nval vad = CalibraVAD.create(VADModelProvider.singingRealtime())\n"})}),"\n",(0,n.jsx)(i.pre,{children:(0,n.jsx)(i.code,{className:"language-swift",children:"let vad = CalibraVAD.create(.general)\r\nlet vad = CalibraVAD.create(.speech())\r\nlet vad = CalibraVAD.create(.singingRealtime())\n"})}),"\n",(0,n.jsx)(i.h3,{id:"with-custom-model-provider",children:"With Custom Model Provider"}),"\n",(0,n.jsx)(i.pre,{children:(0,n.jsx)(i.code,{className:"language-kotlin",children:"// Custom model loader\r\nval vad = CalibraVAD.create(VADModelProvider.Speech { ModelLoader.loadSpeechVAD() })\r\nval vad = CalibraVAD.create(VADModelProvider.SingingRealtime { ModelLoader.loadSingingRealtimeVAD() })\n"})}),"\n",(0,n.jsx)(i.pre,{children:(0,n.jsx)(i.code,{className:"language-swift",children:"let vad = CalibraVAD.create(.speech { ModelLoader.loadSpeechVAD() })\r\nlet vad = CalibraVAD.create(.singingRealtime { ModelLoader.loadSingingRealtimeVAD() })\n"})}),"\n",(0,n.jsx)(i.h3,{id:"with-config--model-provider",children:"With Config + Model Provider"}),"\n",(0,n.jsx)(i.pre,{children:(0,n.jsx)(i.code,{className:"language-kotlin",children:"val config = VADConfig.Builder()\r\n    .preset(VADConfig.SPEECH)\r\n    .threshold(0.4f)\r\n    .build()\r\n\r\nval vad = CalibraVAD.create(config, VADModelProvider.speech())\n"})}),"\n",(0,n.jsx)(i.pre,{children:(0,n.jsx)(i.code,{className:"language-swift",children:"let config = VADConfig.Builder()\r\n    .preset(.speech)\r\n    .threshold(0.4)\r\n    .build()\r\n\r\nlet vad = CalibraVAD.create(config: config, modelProvider: .speech())\n"})}),"\n",(0,n.jsx)(i.h2,{id:"configuration",children:"Configuration"}),"\n",(0,n.jsx)(i.h3,{id:"presets",children:"Presets"}),"\n",(0,n.jsxs)(i.table,{children:[(0,n.jsx)(i.thead,{children:(0,n.jsxs)(i.tr,{children:[(0,n.jsx)(i.th,{children:"Preset"}),(0,n.jsx)(i.th,{children:"Kotlin"}),(0,n.jsx)(i.th,{children:"Swift"}),(0,n.jsx)(i.th,{children:"Description"})]})}),(0,n.jsxs)(i.tbody,{children:[(0,n.jsxs)(i.tr,{children:[(0,n.jsx)(i.td,{children:"Speech"}),(0,n.jsx)(i.td,{children:(0,n.jsx)(i.code,{children:"VADConfig.SPEECH"})}),(0,n.jsx)(i.td,{children:(0,n.jsx)(i.code,{children:".speech"})}),(0,n.jsx)(i.td,{children:"Silero neural network"})]}),(0,n.jsxs)(i.tr,{children:[(0,n.jsx)(i.td,{children:"General"}),(0,n.jsx)(i.td,{children:(0,n.jsx)(i.code,{children:"VADConfig.GENERAL"})}),(0,n.jsx)(i.td,{children:(0,n.jsx)(i.code,{children:".general"})}),(0,n.jsx)(i.td,{children:"RMS-based heuristics"})]}),(0,n.jsxs)(i.tr,{children:[(0,n.jsx)(i.td,{children:"SingingRealtime"}),(0,n.jsx)(i.td,{children:(0,n.jsx)(i.code,{children:"VADConfig.SINGING_REALTIME"})}),(0,n.jsx)(i.td,{children:(0,n.jsx)(i.code,{children:".singingRealtime"})}),(0,n.jsx)(i.td,{children:"SwiftF0 pitch-based"})]})]})]}),"\n",(0,n.jsx)(i.h3,{id:"config-properties",children:"Config Properties"}),"\n",(0,n.jsxs)(i.table,{children:[(0,n.jsx)(i.thead,{children:(0,n.jsxs)(i.tr,{children:[(0,n.jsx)(i.th,{children:"Property"}),(0,n.jsx)(i.th,{children:"Type"}),(0,n.jsx)(i.th,{children:"Default"}),(0,n.jsx)(i.th,{children:"Description"})]})}),(0,n.jsxs)(i.tbody,{children:[(0,n.jsxs)(i.tr,{children:[(0,n.jsx)(i.td,{children:(0,n.jsx)(i.code,{children:"backend"})}),(0,n.jsx)(i.td,{children:(0,n.jsx)(i.code,{children:"VADBackend"})}),(0,n.jsx)(i.td,{children:(0,n.jsx)(i.code,{children:"SPEECH"})}),(0,n.jsx)(i.td,{children:"Detection engine"})]}),(0,n.jsxs)(i.tr,{children:[(0,n.jsx)(i.td,{children:(0,n.jsx)(i.code,{children:"sampleRate"})}),(0,n.jsx)(i.td,{children:(0,n.jsx)(i.code,{children:"Int"})}),(0,n.jsx)(i.td,{children:(0,n.jsx)(i.code,{children:"16000"})}),(0,n.jsx)(i.td,{children:"Audio sample rate in Hz"})]}),(0,n.jsxs)(i.tr,{children:[(0,n.jsx)(i.td,{children:(0,n.jsx)(i.code,{children:"threshold"})}),(0,n.jsx)(i.td,{children:(0,n.jsx)(i.code,{children:"Float"})}),(0,n.jsx)(i.td,{children:(0,n.jsx)(i.code,{children:"0.5"})}),(0,n.jsx)(i.td,{children:"Detection threshold (0.0\u20131.0)"})]}),(0,n.jsxs)(i.tr,{children:[(0,n.jsx)(i.td,{children:(0,n.jsx)(i.code,{children:"minSpeechDuration"})}),(0,n.jsx)(i.td,{children:(0,n.jsx)(i.code,{children:"Float"})}),(0,n.jsx)(i.td,{children:(0,n.jsx)(i.code,{children:"0.25"})}),(0,n.jsx)(i.td,{children:"Minimum speech duration in seconds"})]}),(0,n.jsxs)(i.tr,{children:[(0,n.jsx)(i.td,{children:(0,n.jsx)(i.code,{children:"minSilenceDuration"})}),(0,n.jsx)(i.td,{children:(0,n.jsx)(i.code,{children:"Float"})}),(0,n.jsx)(i.td,{children:(0,n.jsx)(i.code,{children:"0.25"})}),(0,n.jsx)(i.td,{children:"Minimum silence duration in seconds"})]}),(0,n.jsxs)(i.tr,{children:[(0,n.jsx)(i.td,{children:(0,n.jsx)(i.code,{children:"windowSize"})}),(0,n.jsx)(i.td,{children:(0,n.jsx)(i.code,{children:"Int"})}),(0,n.jsx)(i.td,{children:(0,n.jsx)(i.code,{children:"512"})}),(0,n.jsx)(i.td,{children:"Processing window size in samples"})]}),(0,n.jsxs)(i.tr,{children:[(0,n.jsx)(i.td,{children:(0,n.jsx)(i.code,{children:"numThreads"})}),(0,n.jsx)(i.td,{children:(0,n.jsx)(i.code,{children:"Int"})}),(0,n.jsx)(i.td,{children:(0,n.jsx)(i.code,{children:"1"})}),(0,n.jsx)(i.td,{children:"Number of inference threads"})]}),(0,n.jsxs)(i.tr,{children:[(0,n.jsx)(i.td,{children:(0,n.jsx)(i.code,{children:"modelPath"})}),(0,n.jsx)(i.td,{children:(0,n.jsx)(i.code,{children:"String?"})}),(0,n.jsx)(i.td,{children:(0,n.jsx)(i.code,{children:"null"})}),(0,n.jsx)(i.td,{children:"Custom model path (null = bundled model)"})]}),(0,n.jsxs)(i.tr,{children:[(0,n.jsx)(i.td,{children:(0,n.jsx)(i.code,{children:"rmsThreshold"})}),(0,n.jsx)(i.td,{children:(0,n.jsx)(i.code,{children:"Float"})}),(0,n.jsx)(i.td,{children:(0,n.jsx)(i.code,{children:"0.05"})}),(0,n.jsx)(i.td,{children:"RMS threshold for GENERAL backend"})]}),(0,n.jsxs)(i.tr,{children:[(0,n.jsx)(i.td,{children:(0,n.jsx)(i.code,{children:"pitchProbThreshold"})}),(0,n.jsx)(i.td,{children:(0,n.jsx)(i.code,{children:"Float"})}),(0,n.jsx)(i.td,{children:(0,n.jsx)(i.code,{children:"0.5"})}),(0,n.jsx)(i.td,{children:"Pitch probability threshold for GENERAL backend"})]}),(0,n.jsxs)(i.tr,{children:[(0,n.jsx)(i.td,{children:(0,n.jsx)(i.code,{children:"minPitch"})}),(0,n.jsx)(i.td,{children:(0,n.jsx)(i.code,{children:"Float"})}),(0,n.jsx)(i.td,{children:(0,n.jsx)(i.code,{children:"50"})}),(0,n.jsx)(i.td,{children:"Minimum pitch in Hz for GENERAL backend"})]})]})]}),"\n",(0,n.jsx)(i.h3,{id:"builder-methods",children:"Builder Methods"}),"\n",(0,n.jsxs)(i.table,{children:[(0,n.jsx)(i.thead,{children:(0,n.jsxs)(i.tr,{children:[(0,n.jsx)(i.th,{children:"Method"}),(0,n.jsx)(i.th,{children:"Description"})]})}),(0,n.jsxs)(i.tbody,{children:[(0,n.jsxs)(i.tr,{children:[(0,n.jsx)(i.td,{children:(0,n.jsx)(i.code,{children:"preset(config)"})}),(0,n.jsx)(i.td,{children:"Start from a preset configuration"})]}),(0,n.jsxs)(i.tr,{children:[(0,n.jsx)(i.td,{children:(0,n.jsx)(i.code,{children:"backend(backend)"})}),(0,n.jsx)(i.td,{children:"Set backend with its default config"})]}),(0,n.jsxs)(i.tr,{children:[(0,n.jsx)(i.td,{children:(0,n.jsx)(i.code,{children:"sampleRate(rate)"})}),(0,n.jsx)(i.td,{children:"Set audio sample rate in Hz"})]}),(0,n.jsxs)(i.tr,{children:[(0,n.jsx)(i.td,{children:(0,n.jsx)(i.code,{children:"threshold(value)"})}),(0,n.jsx)(i.td,{children:"Set detection threshold (0.0\u20131.0)"})]}),(0,n.jsxs)(i.tr,{children:[(0,n.jsx)(i.td,{children:(0,n.jsx)(i.code,{children:"minSpeechDuration(seconds)"})}),(0,n.jsx)(i.td,{children:"Minimum speech duration"})]}),(0,n.jsxs)(i.tr,{children:[(0,n.jsx)(i.td,{children:(0,n.jsx)(i.code,{children:"minSilenceDuration(seconds)"})}),(0,n.jsx)(i.td,{children:"Minimum silence duration"})]}),(0,n.jsxs)(i.tr,{children:[(0,n.jsx)(i.td,{children:(0,n.jsx)(i.code,{children:"windowSize(samples)"})}),(0,n.jsx)(i.td,{children:"Processing window size"})]}),(0,n.jsxs)(i.tr,{children:[(0,n.jsx)(i.td,{children:(0,n.jsx)(i.code,{children:"numThreads(threads)"})}),(0,n.jsx)(i.td,{children:"Number of inference threads"})]}),(0,n.jsxs)(i.tr,{children:[(0,n.jsx)(i.td,{children:(0,n.jsx)(i.code,{children:"modelPath(path)"})}),(0,n.jsx)(i.td,{children:"Custom model path (null = bundled)"})]}),(0,n.jsxs)(i.tr,{children:[(0,n.jsx)(i.td,{children:(0,n.jsx)(i.code,{children:"rmsThreshold(value)"})}),(0,n.jsx)(i.td,{children:"RMS threshold for GENERAL backend"})]}),(0,n.jsxs)(i.tr,{children:[(0,n.jsx)(i.td,{children:(0,n.jsx)(i.code,{children:"pitchProbThreshold(value)"})}),(0,n.jsx)(i.td,{children:"Pitch probability threshold for GENERAL backend"})]}),(0,n.jsxs)(i.tr,{children:[(0,n.jsx)(i.td,{children:(0,n.jsx)(i.code,{children:"minPitch(hz)"})}),(0,n.jsx)(i.td,{children:"Minimum pitch in Hz for GENERAL backend"})]})]})]}),"\n",(0,n.jsx)(i.h2,{id:"one-shot-analysis",children:"One-Shot Analysis"}),"\n",(0,n.jsx)(i.h3,{id:"getvadratio",children:"getVADRatio"}),"\n",(0,n.jsx)(i.p,{children:"Returns the ratio of voiced frames (0.0 to 1.0). Accepts any sample rate and resamples internally to 16kHz."}),"\n",(0,n.jsx)(i.pre,{children:(0,n.jsx)(i.code,{className:"language-kotlin",children:"val ratio = vad.getVADRatio(samples, sampleRate = 48000)\r\n// 0.0 = silence, 1.0 = continuous voice\n"})}),"\n",(0,n.jsx)(i.pre,{children:(0,n.jsx)(i.code,{className:"language-swift",children:"let ratio = vad.getVADRatio(samples: samples, sampleRate: 48000)\n"})}),"\n",(0,n.jsx)(i.h3,{id:"analyze",children:"analyze"}),"\n",(0,n.jsxs)(i.p,{children:["Returns a rich ",(0,n.jsx)(i.code,{children:"VADResult"})," with ratio, level, and convenience properties:"]}),"\n",(0,n.jsx)(i.pre,{children:(0,n.jsx)(i.code,{className:"language-kotlin",children:'val result = vad.analyze(samples, sampleRate = 48000)\r\nif (result != null) {\r\n    println("Ratio: ${result.ratio}")\r\n    println("Level: ${result.level}")  // NONE, PARTIAL, or FULL\r\n    println("Voice detected: ${result.isVoiceDetected}")\r\n}\n'})}),"\n",(0,n.jsx)(i.h3,{id:"vadresult",children:"VADResult"}),"\n",(0,n.jsxs)(i.table,{children:[(0,n.jsx)(i.thead,{children:(0,n.jsxs)(i.tr,{children:[(0,n.jsx)(i.th,{children:"Property"}),(0,n.jsx)(i.th,{children:"Type"}),(0,n.jsx)(i.th,{children:"Description"})]})}),(0,n.jsxs)(i.tbody,{children:[(0,n.jsxs)(i.tr,{children:[(0,n.jsx)(i.td,{children:(0,n.jsx)(i.code,{children:"ratio"})}),(0,n.jsx)(i.td,{children:(0,n.jsx)(i.code,{children:"Float"})}),(0,n.jsx)(i.td,{children:"Voice activity ratio (0.0\u20131.0)"})]}),(0,n.jsxs)(i.tr,{children:[(0,n.jsx)(i.td,{children:(0,n.jsx)(i.code,{children:"level"})}),(0,n.jsx)(i.td,{children:(0,n.jsx)(i.code,{children:"VoiceActivityLevel"})}),(0,n.jsxs)(i.td,{children:[(0,n.jsx)(i.code,{children:"NONE"}),", ",(0,n.jsx)(i.code,{children:"PARTIAL"}),", or ",(0,n.jsx)(i.code,{children:"FULL"})]})]}),(0,n.jsxs)(i.tr,{children:[(0,n.jsx)(i.td,{children:(0,n.jsx)(i.code,{children:"isVoiceDetected"})}),(0,n.jsx)(i.td,{children:(0,n.jsx)(i.code,{children:"Boolean"})}),(0,n.jsx)(i.td,{children:"True if ratio > 0.5"})]}),(0,n.jsxs)(i.tr,{children:[(0,n.jsx)(i.td,{children:(0,n.jsx)(i.code,{children:"isFullActivity"})}),(0,n.jsx)(i.td,{children:(0,n.jsx)(i.code,{children:"Boolean"})}),(0,n.jsxs)(i.td,{children:["True if level is ",(0,n.jsx)(i.code,{children:"FULL"})]})]})]})]}),"\n",(0,n.jsx)(i.h2,{id:"streaming-mode",children:"Streaming Mode"}),"\n",(0,n.jsxs)(i.p,{children:["For real-time processing, use ",(0,n.jsx)(i.code,{children:"acceptWaveform"})," + ",(0,n.jsx)(i.code,{children:"isVoiceDetected"}),":"]}),"\n",(0,n.jsx)(i.h3,{id:"kotlin-1",children:"Kotlin"}),"\n",(0,n.jsx)(i.pre,{children:(0,n.jsx)(i.code,{className:"language-kotlin",children:"recorder.audioBuffers.collect { buffer ->\r\n    vad.acceptWaveform(buffer.toFloatArray(), sampleRate = 48000)\r\n    if (vad.isVoiceDetected()) {\r\n        showVoiceIndicator()\r\n    }\r\n}\n"})}),"\n",(0,n.jsx)(i.h3,{id:"swift-1",children:"Swift"}),"\n",(0,n.jsx)(i.pre,{children:(0,n.jsx)(i.code,{className:"language-swift",children:"for await buffer in recorder.audioBuffers {\r\n    vad.acceptWaveform(samples: buffer.toFloatArray(), sampleRate: 48000)\r\n    if vad.isVoiceDetected() {\r\n        showVoiceIndicator()\r\n    }\r\n}\n"})}),"\n",(0,n.jsx)(i.h3,{id:"swift-convenience-methods",children:"Swift Convenience Methods"}),"\n",(0,n.jsx)(i.pre,{children:(0,n.jsx)(i.code,{className:"language-swift",children:"// Quick check with custom threshold\r\nlet hasVoice = vad.hasVoiceActivity(samples: samples, sampleRate: 48000, threshold: 0.3)\r\n\r\n// Classify activity level\r\nlet level = vad.classifyVoiceActivity(samples: samples, sampleRate: 48000)\r\n// .none, .partial, or .full\n"})}),"\n",(0,n.jsx)(i.h2,{id:"methods",children:"Methods"}),"\n",(0,n.jsxs)(i.table,{children:[(0,n.jsx)(i.thead,{children:(0,n.jsxs)(i.tr,{children:[(0,n.jsx)(i.th,{children:"Method"}),(0,n.jsx)(i.th,{children:"Description"})]})}),(0,n.jsxs)(i.tbody,{children:[(0,n.jsxs)(i.tr,{children:[(0,n.jsx)(i.td,{children:(0,n.jsx)(i.code,{children:"getVADRatio(samples, sampleRate)"})}),(0,n.jsx)(i.td,{children:"Get voiced frame ratio (0.0\u20131.0)"})]}),(0,n.jsxs)(i.tr,{children:[(0,n.jsx)(i.td,{children:(0,n.jsx)(i.code,{children:"analyze(samples, sampleRate)"})}),(0,n.jsx)(i.td,{children:"Get rich VADResult with level classification"})]}),(0,n.jsxs)(i.tr,{children:[(0,n.jsx)(i.td,{children:(0,n.jsx)(i.code,{children:"acceptWaveform(samples, sampleRate)"})}),(0,n.jsx)(i.td,{children:"Feed samples for streaming detection"})]}),(0,n.jsxs)(i.tr,{children:[(0,n.jsx)(i.td,{children:(0,n.jsx)(i.code,{children:"isVoiceDetected()"})}),(0,n.jsx)(i.td,{children:"Check if voice is currently detected (streaming mode)"})]}),(0,n.jsxs)(i.tr,{children:[(0,n.jsx)(i.td,{children:(0,n.jsx)(i.code,{children:"reset()"})}),(0,n.jsx)(i.td,{children:"Reset state for new audio stream"})]}),(0,n.jsxs)(i.tr,{children:[(0,n.jsx)(i.td,{children:(0,n.jsx)(i.code,{children:"release()"})}),(0,n.jsx)(i.td,{children:"Release all resources"})]})]})]}),"\n",(0,n.jsx)(i.h2,{id:"common-patterns",children:"Common Patterns"}),"\n",(0,n.jsx)(i.h3,{id:"vad-with-recording",children:"VAD with Recording"}),"\n",(0,n.jsx)(i.pre,{children:(0,n.jsx)(i.code,{className:"language-kotlin",children:"class VoiceDetectionViewModel : ViewModel() {\r\n    private var vad: CalibraVAD? = null\r\n\r\n    val isVoiceActive = MutableStateFlow(false)\r\n    val voiceLevel = MutableStateFlow(0f)\r\n\r\n    fun startListening() {\r\n        vad = CalibraVAD.create(VADModelProvider.speech())\r\n\r\n        viewModelScope.launch {\r\n            recorder.audioBuffers.collect { buffer ->\r\n                val ratio = vad!!.getVADRatio(buffer.samples, buffer.sampleRate)\r\n                voiceLevel.value = ratio\r\n                isVoiceActive.value = ratio > 0.5f\r\n            }\r\n        }\r\n    }\r\n\r\n    override fun onCleared() {\r\n        vad?.release()\r\n    }\r\n}\n"})}),"\n",(0,n.jsx)(i.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,n.jsxs)(i.ul,{children:["\n",(0,n.jsxs)(i.li,{children:[(0,n.jsx)(i.a,{href:"./pitch",children:"CalibraPitch"})," \u2014 Detect what note is being sung (not just voice presence)"]}),"\n",(0,n.jsxs)(i.li,{children:[(0,n.jsx)(i.a,{href:"./live-eval",children:"CalibraLiveEval"})," \u2014 Live singing evaluation (uses VAD internally)"]}),"\n",(0,n.jsxs)(i.li,{children:[(0,n.jsx)(i.a,{href:"./vocal-range",children:"CalibraVocalRange"})," \u2014 Detect singer's comfortable range"]}),"\n"]})]})}function o(e={}){const{wrapper:i}={...(0,l.R)(),...e.components};return i?(0,n.jsx)(i,{...e,children:(0,n.jsx)(h,{...e})}):h(e)}},8453(e,i,d){d.d(i,{R:()=>s,x:()=>c});var r=d(6540);const n={},l=r.createContext(n);function s(e){const i=r.useContext(l);return r.useMemo(function(){return"function"==typeof e?e(i):{...i,...e}},[i,e])}function c(e){let i;return i=e.disableParentContext?"function"==typeof e.components?e.components(n):e.components||n:s(e.components),r.createElement(l.Provider,{value:i},e.children)}}}]);