"use strict";(globalThis.webpackChunkdocs=globalThis.webpackChunkdocs||[]).push([[458],{1726(e,n,t){t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>d,default:()=>h,frontMatter:()=>s,metadata:()=>r,toc:()=>o});const r=JSON.parse('{"id":"concepts/pitch-detection","title":"Pitch Detection","description":"Understanding how pitch detection works helps you choose the right settings for your app.","source":"@site/docs/concepts/pitch-detection.md","sourceDirName":"concepts","slug":"/concepts/pitch-detection","permalink":"/voxatrace/concepts/pitch-detection","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1},"sidebar":"docsSidebar","previous":{"title":"iOS Quickstart","permalink":"/voxatrace/getting-started/ios-quickstart"},"next":{"title":"Voice Activity Detection","permalink":"/voxatrace/concepts/voice-activity"}}');var i=t(4848),c=t(8453);const s={sidebar_position:1},d="Pitch Detection",l={},o=[{value:"What is Pitch?",id:"what-is-pitch",level:2},{value:"Frequency vs. Note",id:"frequency-vs-note",level:2},{value:"Detection Algorithms",id:"detection-algorithms",level:2},{value:"YIN (Default)",id:"yin-default",level:3},{value:"SwiftF0 (Neural Network)",id:"swiftf0-neural-network",level:3},{value:"Choosing an Algorithm",id:"choosing-an-algorithm",level:3},{value:"Performance Comparison",id:"performance-comparison",level:3},{value:"Decision Tree",id:"decision-tree",level:3},{value:"Key Concepts",id:"key-concepts",level:2},{value:"Confidence",id:"confidence",level:3},{value:"Octave Errors",id:"octave-errors",level:3},{value:"Voiced vs. Unvoiced",id:"voiced-vs-unvoiced",level:3},{value:"Real-time vs. Batch",id:"real-time-vs-batch",level:2},{value:"Real-time (Detector)",id:"real-time-detector",level:3},{value:"Batch (ContourExtractor)",id:"batch-contourextractor",level:3},{value:"Frequency Range",id:"frequency-range",level:2},{value:"Sample Rate",id:"sample-rate",level:2},{value:"Next Steps",id:"next-steps",level:2}];function a(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,c.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"pitch-detection",children:"Pitch Detection"})}),"\n",(0,i.jsx)(n.p,{children:"Understanding how pitch detection works helps you choose the right settings for your app."}),"\n",(0,i.jsx)(n.h2,{id:"what-is-pitch",children:"What is Pitch?"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Pitch"}),' is the perceptual quality that allows us to order sounds from "low" to "high." When you sing an A4 note, your vocal cords vibrate 440 times per second, producing a ',(0,i.jsx)(n.strong,{children:"fundamental frequency (F0)"})," of 440 Hz."]}),"\n",(0,i.jsx)(n.p,{children:"Pitch detection algorithms analyze audio to find this fundamental frequency."}),"\n",(0,i.jsx)(n.h2,{id:"frequency-vs-note",children:"Frequency vs. Note"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Concept"}),(0,i.jsx)(n.th,{children:"Example"}),(0,i.jsx)(n.th,{children:"What It Is"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Frequency"})}),(0,i.jsx)(n.td,{children:"440 Hz"}),(0,i.jsx)(n.td,{children:"How many times per second the waveform repeats"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Note"})}),(0,i.jsx)(n.td,{children:"A4"}),(0,i.jsx)(n.td,{children:"Musical name (letter + octave number)"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"MIDI Number"})}),(0,i.jsx)(n.td,{children:"69"}),(0,i.jsx)(n.td,{children:"Integer representation (A4 = 69)"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Cents"})}),(0,i.jsx)(n.td,{children:"+5 cents"}),(0,i.jsx)(n.td,{children:"How many hundredths of a semitone off from perfect"})]})]})]}),"\n",(0,i.jsx)(n.p,{children:"VoxaTrace returns frequency in Hz. Convert to notes using:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-kotlin",children:'// Frequency to MIDI number\r\nval midi = 12 * log2(frequency / 440.0) + 69\r\n\r\n// MIDI to note name\r\nval noteNames = arrayOf("C", "C#", "D", "D#", "E", "F", "F#", "G", "G#", "A", "A#", "B")\r\nval noteName = noteNames[midi.toInt() % 12]\r\nval octave = (midi.toInt() / 12) - 1\n'})}),"\n",(0,i.jsx)(n.h2,{id:"detection-algorithms",children:"Detection Algorithms"}),"\n",(0,i.jsx)(n.p,{children:"VoxaTrace offers two pitch detection algorithms:"}),"\n",(0,i.jsx)(n.h3,{id:"yin-default",children:"YIN (Default)"}),"\n",(0,i.jsx)(n.p,{children:"A classic DSP algorithm that works well for most use cases."}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Aspect"}),(0,i.jsx)(n.th,{children:"Details"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Accuracy"})}),(0,i.jsx)(n.td,{children:"Good for clean audio"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Latency"})}),(0,i.jsx)(n.td,{children:"~50ms"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Dependencies"})}),(0,i.jsx)(n.td,{children:"None (pure Kotlin)"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Best For"})}),(0,i.jsx)(n.td,{children:"Simple tuners, low-resource devices"})]})]})]}),"\n",(0,i.jsx)(n.h3,{id:"swiftf0-neural-network",children:"SwiftF0 (Neural Network)"}),"\n",(0,i.jsx)(n.p,{children:"A deep learning model trained on singing and speech data."}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Aspect"}),(0,i.jsx)(n.th,{children:"Details"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Accuracy"})}),(0,i.jsx)(n.td,{children:"Excellent, handles noise well"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Latency"})}),(0,i.jsx)(n.td,{children:"~50ms"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Dependencies"})}),(0,i.jsx)(n.td,{children:"ONNX Runtime, ai-models module"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Best For"})}),(0,i.jsx)(n.td,{children:"Singing apps, noisy environments"})]})]})]}),"\n",(0,i.jsx)(n.h3,{id:"choosing-an-algorithm",children:"Choosing an Algorithm"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-kotlin",children:"// YIN - no dependencies, good for simple apps\r\nval detector = CalibraPitch.createDetector(\r\n    PitchDetectorConfig.BALANCED\r\n)\r\n\r\n// SwiftF0 - better accuracy, requires model\r\nval detector = CalibraPitch.createDetector(\r\n    PitchDetectorConfig.Builder()\r\n        .algorithm(PitchAlgorithm.SWIFT_F0)\r\n        .build(),\r\n    modelProvider = { ModelLoader.loadSwiftF0() }\r\n)\n"})}),"\n",(0,i.jsx)(n.h3,{id:"performance-comparison",children:"Performance Comparison"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Metric"}),(0,i.jsx)(n.th,{children:"YIN"}),(0,i.jsx)(n.th,{children:"SwiftF0"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Latency"}),(0,i.jsx)(n.td,{children:"~50ms"}),(0,i.jsx)(n.td,{children:"~50ms"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"CPU usage"}),(0,i.jsx)(n.td,{children:"Low"}),(0,i.jsx)(n.td,{children:"Medium"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Memory"}),(0,i.jsx)(n.td,{children:"Minimal"}),(0,i.jsx)(n.td,{children:"~10MB (model)"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Accuracy (clean audio)"}),(0,i.jsx)(n.td,{children:"92\u201395%"}),(0,i.jsx)(n.td,{children:"96\u201398%"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Accuracy (noisy audio)"}),(0,i.jsx)(n.td,{children:"70\u201380%"}),(0,i.jsx)(n.td,{children:"85\u201392%"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Vibrato handling"}),(0,i.jsx)(n.td,{children:"Fair"}),(0,i.jsx)(n.td,{children:"Excellent"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Dependencies"}),(0,i.jsx)(n.td,{children:"None"}),(0,i.jsx)(n.td,{children:"ONNX Runtime"})]})]})]}),"\n",(0,i.jsx)(n.h3,{id:"decision-tree",children:"Decision Tree"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-text",children:"What are you building?\r\n\u2502\r\n\u251c\u2500\u25ba Simple tuner app\r\n\u2502   \u2514\u2500\u25ba Use YIN (minimal dependencies, good enough accuracy)\r\n\u2502\r\n\u251c\u2500\u25ba Karaoke / singing app\r\n\u2502   \u2514\u2500\u25ba Use SwiftF0 (better handling of vibrato and background noise)\r\n\u2502\r\n\u251c\u2500\u25ba Low-end device support required?\r\n\u2502   \u2514\u2500\u25ba Use YIN (lower memory and CPU)\r\n\u2502\r\n\u2514\u2500\u25ba Accuracy is critical?\r\n    \u2514\u2500\u25ba Use SwiftF0 (neural network handles edge cases better)\n"})}),"\n",(0,i.jsx)(n.h2,{id:"key-concepts",children:"Key Concepts"}),"\n",(0,i.jsx)(n.h3,{id:"confidence",children:"Confidence"}),"\n",(0,i.jsxs)(n.p,{children:["Each pitch detection returns a ",(0,i.jsx)(n.strong,{children:"confidence"})," value (0.0 to 1.0) indicating how certain the algorithm is about the result."]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"> 0.8"}),": High confidence, reliable pitch"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"0.5 - 0.8"}),": Moderate confidence, probably correct"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"< 0.5"}),": Low confidence, might be noise or wrong octave"]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"Use confidence to filter unreliable detections:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-kotlin",children:"val point = detector.detect(samples, sampleRate)\r\nif (point.confidence > 0.7f) {\r\n    // Trust this pitch\r\n    updateDisplay(point.pitch)\r\n}\n"})}),"\n",(0,i.jsx)(n.h3,{id:"octave-errors",children:"Octave Errors"}),"\n",(0,i.jsxs)(n.p,{children:["Sometimes the algorithm detects the wrong ",(0,i.jsx)(n.strong,{children:"octave"})," - reporting 880 Hz instead of 440 Hz (one octave too high) or 220 Hz (one octave too low)."]}),"\n",(0,i.jsx)(n.p,{children:"VoxaTrace provides octave correction:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-kotlin",children:"// Enable in detector config\r\nval config = PitchDetectorConfig.Builder()\r\n    .enableProcessing()  // Enables smoothing + octave correction\r\n    .build()\r\n\r\n// Or fix in post-processing\r\nval corrected = CalibraPitch.PostProcess.correctOctaveErrors(pitches)\n"})}),"\n",(0,i.jsx)(n.h3,{id:"voiced-vs-unvoiced",children:"Voiced vs. Unvoiced"}),"\n",(0,i.jsxs)(n.p,{children:["Not all audio contains pitch. Consonants, noise, and silence are ",(0,i.jsx)(n.strong,{children:"unvoiced"}),"."]}),"\n",(0,i.jsxs)(n.p,{children:["VoxaTrace returns ",(0,i.jsx)(n.code,{children:"-1"})," for unvoiced frames:"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-kotlin",children:"val point = detector.detect(samples, sampleRate)\r\nif (point.pitch > 0) {\r\n    // Voiced - show pitch\r\n} else {\r\n    // Unvoiced - show silence indicator\r\n}\n"})}),"\n",(0,i.jsx)(n.h2,{id:"real-time-vs-batch",children:"Real-time vs. Batch"}),"\n",(0,i.jsx)(n.h3,{id:"real-time-detector",children:"Real-time (Detector)"}),"\n",(0,i.jsx)(n.p,{children:"For live audio streams - process one buffer at a time:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-kotlin",children:"val detector = CalibraPitch.createDetector()\r\nrecorder.audioBuffers.collect { buffer ->\r\n    val point = detector.detect(buffer.toFloatArray(), buffer.sampleRate)\r\n    updateUI(point)\r\n}\r\ndetector.close()\n"})}),"\n",(0,i.jsx)(n.h3,{id:"batch-contourextractor",children:"Batch (ContourExtractor)"}),"\n",(0,i.jsx)(n.p,{children:"For recorded audio files - process the entire file at once:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-kotlin",children:"val extractor = CalibraPitch.createContourExtractor(ContourExtractorConfig.SCORING)\r\nval contour = extractor.extract(audioSamples, sampleRate = 16000)\r\n// contour.samples contains all pitch points with timestamps\r\nextractor.release()\n"})}),"\n",(0,i.jsx)(n.h2,{id:"frequency-range",children:"Frequency Range"}),"\n",(0,i.jsx)(n.p,{children:"Human singing typically spans:"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Voice Type"}),(0,i.jsx)(n.th,{children:"Low"}),(0,i.jsx)(n.th,{children:"High"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Bass"}),(0,i.jsx)(n.td,{children:"E2 (82 Hz)"}),(0,i.jsx)(n.td,{children:"E4 (330 Hz)"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Baritone"}),(0,i.jsx)(n.td,{children:"A2 (110 Hz)"}),(0,i.jsx)(n.td,{children:"A4 (440 Hz)"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Tenor"}),(0,i.jsx)(n.td,{children:"C3 (131 Hz)"}),(0,i.jsx)(n.td,{children:"C5 (523 Hz)"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Alto"}),(0,i.jsx)(n.td,{children:"F3 (175 Hz)"}),(0,i.jsx)(n.td,{children:"F5 (698 Hz)"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Soprano"}),(0,i.jsx)(n.td,{children:"C4 (262 Hz)"}),(0,i.jsx)(n.td,{children:"C6 (1047 Hz)"})]})]})]}),"\n",(0,i.jsx)(n.p,{children:"VoxaTrace detects 50 Hz to 2000 Hz by default. Customize for your use case:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-kotlin",children:"val config = PitchDetectorConfig.Builder()\r\n    .voiceType(VoiceType.Soprano)  // Optimizes for soprano range\r\n    .build()\n"})}),"\n",(0,i.jsx)(n.h2,{id:"sample-rate",children:"Sample Rate"}),"\n",(0,i.jsxs)(n.p,{children:["Pitch detection works best at ",(0,i.jsx)(n.strong,{children:"16 kHz"}),". VoxaTrace resamples automatically:"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-kotlin",children:"// Pass any sample rate - VoxaTrace handles resampling\r\nval point = detector.detect(samples, sampleRate = 48000)  // Resampled internally\n"})}),"\n",(0,i.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.a,{href:"/docs/guides/detecting-pitch",children:"Detecting Pitch Guide"})," - Implementation guide"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.a,{href:"/api/calibra/CalibraPitch",children:"CalibraPitch API Reference"})," - Full API documentation"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.a,{href:"/docs/concepts/voice-activity",children:"Voice Activity Detection"})," - Detect when someone is singing"]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,c.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(a,{...e})}):a(e)}},8453(e,n,t){t.d(n,{R:()=>s,x:()=>d});var r=t(6540);const i={},c=r.createContext(i);function s(e){const n=r.useContext(c);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function d(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:s(e.components),r.createElement(c.Provider,{value:n},e.children)}}}]);