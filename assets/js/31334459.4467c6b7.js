"use strict";(globalThis.webpackChunkdocs=globalThis.webpackChunkdocs||[]).push([[63],{4270(e,n,r){r.r(n),r.d(n,{assets:()=>a,contentTitle:()=>l,default:()=>h,frontMatter:()=>c,metadata:()=>i,toc:()=>s});const i=JSON.parse('{"id":"guides/detecting-pitch","title":"Detecting Pitch","description":"A complete guide to pitch detection with CalibraPitch.","source":"@site/docs/guides/detecting-pitch.md","sourceDirName":"guides","slug":"/guides/detecting-pitch","permalink":"/voxatrace/guides/detecting-pitch","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3},"sidebar":"docsSidebar","previous":{"title":"Recording Audio","permalink":"/voxatrace/guides/recording-audio"},"next":{"title":"Live Evaluation","permalink":"/voxatrace/guides/live-evaluation"}}');var t=r(4848),o=r(8453);const c={sidebar_position:3},l="Detecting Pitch",a={},s=[{value:"What You&#39;ll Learn",id:"what-youll-learn",level:2},{value:"Prerequisites",id:"prerequisites",level:2},{value:"Quick Start",id:"quick-start",level:2},{value:"Kotlin",id:"kotlin",level:3},{value:"Swift",id:"swift",level:3},{value:"Real-time Detection",id:"real-time-detection",level:2},{value:"Basic Setup",id:"basic-setup",level:3},{value:"Processing Audio",id:"processing-audio",level:3},{value:"Understanding Results",id:"understanding-results",level:3},{value:"Choosing an Algorithm",id:"choosing-an-algorithm",level:2},{value:"YIN (Default)",id:"yin-default",level:3},{value:"SwiftF0 (Neural Network)",id:"swiftf0-neural-network",level:3},{value:"Configuration Options",id:"configuration-options",level:2},{value:"Presets",id:"presets",level:3},{value:"Voice Type",id:"voice-type",level:3},{value:"Processing (Smoothing + Octave Correction)",id:"processing-smoothing--octave-correction",level:3},{value:"Quiet Handling",id:"quiet-handling",level:3},{value:"Batch Extraction",id:"batch-extraction",level:2},{value:"Cleanup Options",id:"cleanup-options",level:3},{value:"Post-Processing",id:"post-processing",level:2},{value:"Working with Arrays",id:"working-with-arrays",level:3},{value:"Live Pitch Contour",id:"live-pitch-contour",level:2},{value:"Converting to Notes",id:"converting-to-notes",level:2},{value:"Common Patterns",id:"common-patterns",level:2},{value:"Tuner App",id:"tuner-app",level:3},{value:"Pitch Visualization",id:"pitch-visualization",level:3},{value:"Troubleshooting",id:"troubleshooting",level:2},{value:"No Pitch Detected",id:"no-pitch-detected",level:3},{value:"Wrong Octave",id:"wrong-octave",level:3},{value:"Noisy/Jumpy Readings",id:"noisyjumpy-readings",level:3},{value:"Next Steps",id:"next-steps",level:2}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",ul:"ul",...(0,o.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"detecting-pitch",children:"Detecting Pitch"})}),"\n",(0,t.jsx)(n.p,{children:"A complete guide to pitch detection with CalibraPitch."}),"\n",(0,t.jsx)(n.h2,{id:"what-youll-learn",children:"What You'll Learn"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Detect pitch in real-time from microphone input"}),"\n",(0,t.jsx)(n.li,{children:"Extract pitch contours from recorded audio"}),"\n",(0,t.jsx)(n.li,{children:"Choose between YIN and SwiftF0 algorithms"}),"\n",(0,t.jsx)(n.li,{children:"Handle octave errors and noise"}),"\n",(0,t.jsx)(n.li,{children:"Convert frequency to musical notes"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"VoxaTrace installed"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"quick-start",children:"Quick Start"}),"\n",(0,t.jsx)(n.h3,{id:"kotlin",children:"Kotlin"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-kotlin",children:'val detector = CalibraPitch.createDetector()\r\n\r\nrecorder.audioBuffers.collect { buffer ->\r\n    val samples = buffer.toFloatArray()\r\n    val point = detector.detect(samples, buffer.sampleRate)\r\n\r\n    if (point.pitch > 0) {\r\n        println("Pitch: ${point.pitch} Hz, Confidence: ${point.confidence}")\r\n    }\r\n}\r\n\r\ndetector.close()\n'})}),"\n",(0,t.jsx)(n.h3,{id:"swift",children:"Swift"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-swift",children:'let detector = CalibraPitch.createDetector()\r\n\r\nfor await buffer in recorder.audioBuffersStream() {\r\n    let samples = buffer.samples\r\n    let point = detector.detect(samples: samples, sampleRate: Int(buffer.sampleRate))\r\n\r\n    if point.pitch > 0 {\r\n        print("Pitch: \\(point.pitch) Hz, Confidence: \\(point.confidence)")\r\n    }\r\n}\r\n\r\ndetector.close()\n'})}),"\n",(0,t.jsx)(n.h2,{id:"real-time-detection",children:"Real-time Detection"}),"\n",(0,t.jsx)(n.h3,{id:"basic-setup",children:"Basic Setup"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-kotlin",children:"// Create detector with defaults\r\nval detector = CalibraPitch.createDetector()\r\n\r\n// Or with preset\r\nval detector = CalibraPitch.createDetector(PitchDetectorConfig.BALANCED)\n"})}),"\n",(0,t.jsx)(n.h3,{id:"processing-audio",children:"Processing Audio"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-kotlin",children:"// From recorder\r\nrecorder.audioBuffers.collect { buffer ->\r\n    val samples = FloatArray(buffer.sampleCount)\r\n    buffer.fillFloatSamples(samples)\r\n\r\n    val point = detector.detect(samples, buffer.sampleRate)\r\n    updateUI(point)\r\n}\r\n\r\n// From any audio source\r\nval point = detector.detect(audioSamples, sampleRate = 48000)\n"})}),"\n",(0,t.jsx)(n.h3,{id:"understanding-results",children:"Understanding Results"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-kotlin",children:"data class PitchPoint(\r\n    val pitch: Float,      // Frequency in Hz (-1 if unvoiced)\r\n    val confidence: Float, // 0.0 to 1.0\r\n    val timeSeconds: Float // Timestamp (for contours)\r\n)\r\n\r\n// Check if voiced\r\nif (point.pitch > 0) {\r\n    // Valid pitch detected\r\n} else {\r\n    // Unvoiced (silence, noise, or consonant)\r\n}\r\n\r\n// Check confidence\r\nif (point.confidence > 0.7f) {\r\n    // High confidence - trust this pitch\r\n}\n"})}),"\n",(0,t.jsx)(n.h2,{id:"choosing-an-algorithm",children:"Choosing an Algorithm"}),"\n",(0,t.jsx)(n.h3,{id:"yin-default",children:"YIN (Default)"}),"\n",(0,t.jsx)(n.p,{children:"Classic DSP algorithm. No external dependencies."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-kotlin",children:"val detector = CalibraPitch.createDetector(\r\n    PitchDetectorConfig.Builder()\r\n        .algorithm(PitchAlgorithm.YIN)\r\n        .build()\r\n)\n"})}),"\n",(0,t.jsx)(n.p,{children:"Best for:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Simple tuner apps"}),"\n",(0,t.jsx)(n.li,{children:"Low-resource devices"}),"\n",(0,t.jsx)(n.li,{children:"When you can't add ONNX Runtime"}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"swiftf0-neural-network",children:"SwiftF0 (Neural Network)"}),"\n",(0,t.jsx)(n.p,{children:"Deep learning model with better accuracy in noisy conditions."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-kotlin",children:"val detector = CalibraPitch.createDetector(\r\n    PitchDetectorConfig.Builder()\r\n        .algorithm(PitchAlgorithm.SWIFT_F0)\r\n        .build(),\r\n    modelProvider = { ModelLoader.loadSwiftF0() }\r\n)\n"})}),"\n",(0,t.jsx)(n.p,{children:"Best for:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Singing apps (more robust to vibrato, noise)"}),"\n",(0,t.jsx)(n.li,{children:"Production apps where accuracy matters"}),"\n",(0,t.jsx)(n.li,{children:"When ONNX Runtime is acceptable"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"configuration-options",children:"Configuration Options"}),"\n",(0,t.jsx)(n.h3,{id:"presets",children:"Presets"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-kotlin",children:"PitchDetectorConfig.BALANCED  // Good tradeoff (default)\r\nPitchDetectorConfig.PRECISE   // Higher accuracy, more CPU\r\nPitchDetectorConfig.RELAXED      // Lower latency, less accuracy\n"})}),"\n",(0,t.jsx)(n.h3,{id:"voice-type",children:"Voice Type"}),"\n",(0,t.jsx)(n.p,{children:"Optimize for specific vocal ranges:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-kotlin",children:"val config = PitchDetectorConfig.Builder()\r\n    .voiceType(VoiceType.WesternSoprano)  // High female voice\r\n    .voiceType(VoiceType.WesternTenor)    // High male voice\r\n    .voiceType(VoiceType.WesternBass)     // Low male voice\r\n    .voiceType(VoiceType.Auto)         // Detect automatically\r\n    .voiceType(VoiceType.carnaticMale) // Indian classical male\r\n    .build()\n"})}),"\n",(0,t.jsx)(n.h3,{id:"processing-smoothing--octave-correction",children:"Processing (Smoothing + Octave Correction)"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-kotlin",children:"val config = PitchDetectorConfig.Builder()\r\n    .enableProcessing()  // Enable smoothing and octave correction\r\n    .build()\r\n\r\n// Or control at runtime\r\ndetector.processingEnabled = true\n"})}),"\n",(0,t.jsx)(n.h3,{id:"quiet-handling",children:"Quiet Handling"}),"\n",(0,t.jsx)(n.p,{children:"How to handle low-amplitude audio:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-kotlin",children:"val config = PitchDetectorConfig.Builder()\r\n    .quietHandling(QuietHandling.NORMAL)      // Standard gating\r\n    .quietHandling(QuietHandling.SENSITIVE)   // More sensitive for soft singers\r\n    .quietHandling(QuietHandling.NOISY)       // For noisy environments\r\n    .build()\n"})}),"\n",(0,t.jsx)(n.h2,{id:"batch-extraction",children:"Batch Extraction"}),"\n",(0,t.jsx)(n.p,{children:"Extract complete pitch contours from recorded audio:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-kotlin",children:'val extractor = CalibraPitch.createContourExtractor(\r\n    ContourExtractorConfig.SCORING,\r\n    modelProvider = { ModelLoader.loadSwiftF0() }\r\n)\r\n\r\n// Load audio (must be 16kHz or will be resampled)\r\nval audio = decoder.decode("recording.m4a")\r\n\r\n// Extract contour\r\nval contour = extractor.extract(audio.samples, audio.sampleRate)\r\n\r\n// Access points\r\ncontour.samples.forEach { point ->\r\n    println("Time: ${point.timeSeconds}s, Pitch: ${point.pitch} Hz")\r\n}\r\n\r\nextractor.release()\n'})}),"\n",(0,t.jsx)(n.h3,{id:"cleanup-options",children:"Cleanup Options"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-kotlin",children:"// For scoring - removes artifacts, corrects octaves\r\nval config = ContourExtractorConfig.SCORING\r\n\r\n// For display - includes smoothing\r\nval config = ContourExtractorConfig.DISPLAY\r\n\r\n// Raw - no processing\r\nval config = ContourExtractorConfig.RAW\r\n\r\n// Custom\r\nval config = ContourExtractorConfig.Builder()\r\n    .preset(ContourExtractorConfig.SCORING)\r\n    .hopMs(10)  // 10ms between pitch samples\r\n    .cleanup(ContourCleanup.SCORING)\r\n    .build()\n"})}),"\n",(0,t.jsx)(n.h2,{id:"post-processing",children:"Post-Processing"}),"\n",(0,t.jsx)(n.p,{children:"Apply cleanup to existing contours:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-kotlin",children:"// Apply preset cleanup\r\nval cleaned = CalibraPitch.PostProcess.cleanup(contour, ContourCleanup.SCORING)\r\n\r\n// Individual operations\r\nval smoothed = CalibraPitch.PostProcess.smooth(contour)\r\nval octaveFixed = CalibraPitch.PostProcess.fixOctaveErrors(contour)\r\nval noBlips = CalibraPitch.PostProcess.removeBlips(contour, minDurationMs = 80f)\n"})}),"\n",(0,t.jsx)(n.h3,{id:"working-with-arrays",children:"Working with Arrays"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-kotlin",children:"val pitches = floatArrayOf(440f, 442f, 880f, 438f)  // Has octave error\r\n\r\n// Full processing\r\nval processed = CalibraPitch.PostProcess.process(pitches)\r\n\r\n// Individual operations\r\nval smoothed = CalibraPitch.PostProcess.smooth(pitches, windowSize = 5)\r\nval corrected = CalibraPitch.PostProcess.correctOctaveErrors(pitches)\r\nval filtered = CalibraPitch.PostProcess.medianFilter(pitches, kernelSize = 3)\n"})}),"\n",(0,t.jsx)(n.h2,{id:"live-pitch-contour",children:"Live Pitch Contour"}),"\n",(0,t.jsx)(n.p,{children:"For visualization, access the growing contour:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-kotlin",children:"// Observe live contour for drawing\r\ndetector.livePitchContour.collect { contour ->\r\n    drawPitchCurve(contour.samples)\r\n}\r\n\r\n// Set max duration (for scrolling displays)\r\ndetector.setContourMaxDuration(30f)  // Keep last 30 seconds\r\n\r\n// Clear when starting new recording\r\ndetector.clearPitchContour()\n"})}),"\n",(0,t.jsx)(n.h2,{id:"converting-to-notes",children:"Converting to Notes"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-kotlin",children:'fun pitchToNote(frequency: Float): NoteInfo {\r\n    if (frequency <= 0) return NoteInfo.UNVOICED\r\n\r\n    val a4 = 440.0\r\n    val semitones = 12 * kotlin.math.log2(frequency / a4) + 69\r\n\r\n    val noteNames = arrayOf("C", "C#", "D", "D#", "E", "F", "F#", "G", "G#", "A", "A#", "B")\r\n    val noteIndex = (semitones.toInt() % 12 + 12) % 12\r\n    val octave = (semitones.toInt() / 12) - 1\r\n    val midiNumber = semitones.toInt()\r\n    val centsOff = ((semitones - semitones.toInt()) * 100).toInt()\r\n\r\n    return NoteInfo(\r\n        name = "${noteNames[noteIndex]}$octave",\r\n        midi = midiNumber,\r\n        centsOff = centsOff,\r\n        frequency = frequency\r\n    )\r\n}\r\n\r\ndata class NoteInfo(\r\n    val name: String,\r\n    val midi: Int,\r\n    val centsOff: Int,  // -50 to +50\r\n    val frequency: Float\r\n) {\r\n    companion object {\r\n        val UNVOICED = NoteInfo("--", 0, 0, -1f)\r\n    }\r\n}\n'})}),"\n",(0,t.jsx)(n.h2,{id:"common-patterns",children:"Common Patterns"}),"\n",(0,t.jsx)(n.h3,{id:"tuner-app",children:"Tuner App"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-kotlin",children:'class TunerViewModel : ViewModel() {\r\n    private var detector: CalibraPitch.Detector? = null\r\n    private var recorder: SonixRecorder? = null\r\n\r\n    val note = MutableStateFlow("--")\r\n    val frequency = MutableStateFlow(0f)\r\n    val centsOff = MutableStateFlow(0)\r\n\r\n    fun start() {\r\n        detector = CalibraPitch.createDetector()\r\n        recorder = SonixRecorder.createTemporary()\r\n\r\n        recorder?.start()\r\n\r\n        viewModelScope.launch {\r\n            recorder?.audioBuffers?.collect { buffer ->\r\n                val samples = FloatArray(buffer.sampleCount)\r\n                buffer.fillFloatSamples(samples)\r\n\r\n                val point = detector?.detect(samples, buffer.sampleRate) ?: return@collect\r\n\r\n                if (point.pitch > 0 && point.confidence > 0.6f) {\r\n                    val noteInfo = pitchToNote(point.pitch)\r\n                    note.value = noteInfo.name\r\n                    frequency.value = noteInfo.frequency\r\n                    centsOff.value = noteInfo.centsOff\r\n                } else {\r\n                    note.value = "--"\r\n                    frequency.value = 0f\r\n                    centsOff.value = 0\r\n                }\r\n            }\r\n        }\r\n    }\r\n\r\n    fun stop() {\r\n        recorder?.stop()\r\n        recorder?.release()\r\n        detector?.close()\r\n    }\r\n}\n'})}),"\n",(0,t.jsx)(n.h3,{id:"pitch-visualization",children:"Pitch Visualization"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-kotlin",children:"class PitchGraphView : View {\r\n    private val pitchHistory = mutableListOf<Float>()\r\n    private val maxHistory = 100\r\n\r\n    fun addPitch(pitch: Float) {\r\n        pitchHistory.add(pitch)\r\n        if (pitchHistory.size > maxHistory) {\r\n            pitchHistory.removeAt(0)\r\n        }\r\n        invalidate()\r\n    }\r\n\r\n    override fun onDraw(canvas: Canvas) {\r\n        // Draw pitch history as scrolling graph\r\n        pitchHistory.forEachIndexed { index, pitch ->\r\n            if (pitch > 0) {\r\n                val x = index * (width / maxHistory.toFloat())\r\n                val y = height - (pitch / 1000f * height)  // Normalize to view\r\n                canvas.drawCircle(x, y, 4f, paint)\r\n            }\r\n        }\r\n    }\r\n}\n"})}),"\n",(0,t.jsx)(n.h2,{id:"troubleshooting",children:"Troubleshooting"}),"\n",(0,t.jsx)(n.h3,{id:"no-pitch-detected",children:"No Pitch Detected"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Check microphone permission"}),"\n",(0,t.jsx)(n.li,{children:"Verify audio is reaching detector (print buffer sizes)"}),"\n",(0,t.jsx)(n.li,{children:"Try lowering confidence threshold"}),"\n",(0,t.jsxs)(n.li,{children:["Check if audio is too quiet (use ",(0,t.jsx)(n.code,{children:"QuietHandling.SENSITIVE"}),")"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"wrong-octave",children:"Wrong Octave"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Enable processing: ",(0,t.jsx)(n.code,{children:".enableProcessing()"})]}),"\n",(0,t.jsxs)(n.li,{children:["Use post-processing: ",(0,t.jsx)(n.code,{children:"PostProcess.correctOctaveErrors()"})]}),"\n",(0,t.jsx)(n.li,{children:"Try SwiftF0 algorithm (better octave handling)"}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"noisyjumpy-readings",children:"Noisy/Jumpy Readings"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Enable smoothing: ",(0,t.jsx)(n.code,{children:".enableProcessing()"})]}),"\n",(0,t.jsx)(n.li,{children:"Filter by confidence (> 0.7)"}),"\n",(0,t.jsx)(n.li,{children:"Use median filter in post-processing"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"../concepts/pitch-detection",children:"Pitch Detection Concepts"})," - Theory and background"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"../cookbook/tuner-app",children:"Tuner App Recipe"})," - Complete example"]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},8453(e,n,r){r.d(n,{R:()=>c,x:()=>l});var i=r(6540);const t={},o=i.createContext(t);function c(e){const n=i.useContext(o);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:c(e.components),i.createElement(o.Provider,{value:n},e.children)}}}]);