"use strict";(globalThis.webpackChunkdocs=globalThis.webpackChunkdocs||[]).push([[358],{2936(e,n,i){i.r(n),i.d(n,{assets:()=>r,contentTitle:()=>a,default:()=>h,frontMatter:()=>c,metadata:()=>t,toc:()=>o});const t=JSON.parse('{"id":"calibra/overview","title":"Calibra Overview","description":"Calibra is the audio analysis module of VoxaTrace, providing:","source":"@site/docs/calibra/overview.md","sourceDirName":"calibra","slug":"/calibra/overview","permalink":"/calibra/overview","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1},"sidebar":"docsSidebar","previous":{"title":"Sonix Overview","permalink":"/sonix/overview"}}');var s=i(4848),l=i(8453);const c={sidebar_position:1},a="Calibra Overview",r={},o=[{value:"Calibra in Action",id:"calibra-in-action",level:2},{value:"Real-Time Pitch Feedback",id:"real-time-pitch-feedback",level:3},{value:"Voice Activity Detection",id:"voice-activity-detection",level:3},{value:"Live Evaluation Flow",id:"live-evaluation-flow",level:3},{value:"Key Features",id:"key-features",level:2},{value:"Pitch Detection",id:"pitch-detection",level:3},{value:"Voice Activity Detection (VAD)",id:"voice-activity-detection-vad",level:3},{value:"Vocal Range Detection",id:"vocal-range-detection",level:3},{value:"Singing Evaluation",id:"singing-evaluation",level:3},{value:"Next Steps",id:"next-steps",level:2}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,l.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"calibra-overview",children:"Calibra Overview"})}),"\n",(0,s.jsx)(n.p,{children:"Calibra is the audio analysis module of VoxaTrace, providing:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Pitch Detection"})," \u2014 Real-time fundamental frequency detection"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Voice Activity Detection"})," \u2014 Detect when someone is speaking or singing"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Vocal Range Detection"})," \u2014 Determine a singer's comfortable range"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Singing Evaluation"})," \u2014 Score singing accuracy against a reference"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"calibra-in-action",children:"Calibra in Action"}),"\n",(0,s.jsx)(n.h3,{id:"real-time-pitch-feedback",children:"Real-Time Pitch Feedback"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-text",children:'User sings: "Hap-py birth-day to you"\n\nTimeline:     0.0s    0.5s    1.0s    1.5s    2.0s\n              \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\nReference:    C4      C4      D4      C4      F4\nDetected:     C4      C4      D4      C#4     F4\n              \u2713       \u2713       \u2713       ~       \u2713\n\nScore: 4/5 notes matched = 80%\n'})}),"\n",(0,s.jsx)(n.h3,{id:"voice-activity-detection",children:"Voice Activity Detection"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-text",children:"Audio input:  [noise][singing~~~~~][breath][singing~~~~~][noise]\nVAD output:   [  0  ][     1      ][  0   ][     1      ][  0  ]\n\nAction:       Skip    Process      Skip    Process       Skip\n"})}),"\n",(0,s.jsx)(n.h3,{id:"live-evaluation-flow",children:"Live Evaluation Flow"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-text",children:"                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    Reference \u2500\u2500\u2500\u2500\u2500 \u2502              \u2502\n    Audio           \u2502   Compare    \u2502 \u2500\u2500\u2500\u2500\u2500 Score (0.0\u20131.0)\n                    \u2502   Pitches    \u2502\n    Student  \u2500\u2500\u2500\u2500\u2500  \u2502              \u2502\n    Audio           \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                          \u2502\n                          \u25bc\n              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n              \u2502 Segment 1: 85%        \u2502\n              \u2502 Segment 2: 92%        \u2502\n              \u2502 Segment 3: 78%        \u2502\n              \u2502 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2502\n              \u2502 Overall: 85%          \u2502\n              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"})}),"\n",(0,s.jsx)(n.h2,{id:"key-features",children:"Key Features"}),"\n",(0,s.jsx)(n.h3,{id:"pitch-detection",children:"Pitch Detection"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Real-time F0 detection with two algorithms (YIN and SwiftF0)"}),"\n",(0,s.jsx)(n.li,{children:"Works with singing and speech"}),"\n",(0,s.jsx)(n.li,{children:"Frequency range: 50Hz \u2013 2000Hz"}),"\n",(0,s.jsx)(n.li,{children:"Low latency (~50ms)"}),"\n"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-kotlin",children:"val detector = CalibraPitch.createDetector()\nval point = detector.detect(samples, sampleRate = 16000)\n// point.pitch = 440.0, point.confidence = 0.92\n"})}),"\n",(0,s.jsx)(n.h3,{id:"voice-activity-detection-vad",children:"Voice Activity Detection (VAD)"}),"\n",(0,s.jsx)(n.p,{children:"Multiple detection backends for different use cases:"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Backend"}),(0,s.jsx)(n.th,{children:"Best For"}),(0,s.jsx)(n.th,{children:"Latency"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"General (Energy)"}),(0,s.jsx)(n.td,{children:"Simple apps, low power"}),(0,s.jsx)(n.td,{children:"<1ms"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Speech (Silero)"}),(0,s.jsx)(n.td,{children:"Voice assistants, transcription"}),(0,s.jsx)(n.td,{children:"~5ms"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Singing (YAMNet)"}),(0,s.jsx)(n.td,{children:"Karaoke, singing detection"}),(0,s.jsx)(n.td,{children:"~20ms"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"SingingRealtime"}),(0,s.jsx)(n.td,{children:"Real-time singing apps"}),(0,s.jsx)(n.td,{children:"~5ms"})]})]})]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-kotlin",children:"val vad = CalibraVAD.create(VADConfig.SINGING)\nval result = vad.analyze(samples, sampleRate)\n// result.isSpeaking = true, result.level = Level.MODERATE\n"})}),"\n",(0,s.jsx)(n.h3,{id:"vocal-range-detection",children:"Vocal Range Detection"}),"\n",(0,s.jsx)(n.p,{children:"Guided range finding that detects a singer's comfortable range:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-kotlin",children:"val session = VocalRangeSession.create()\nsession.start()\n// Guide user through high and low notes\nval range = session.finish()\n// range.lowNote = 48 (C3), range.highNote = 72 (C5)\n"})}),"\n",(0,s.jsx)(n.h3,{id:"singing-evaluation",children:"Singing Evaluation"}),"\n",(0,s.jsx)(n.p,{children:"Two evaluation modes:"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Singalong Mode"})," \u2014 Evaluate while singing along with reference audio"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Real-time pitch comparison"}),"\n",(0,s.jsx)(n.li,{children:"Note-by-note scoring"}),"\n",(0,s.jsx)(n.li,{children:"Immediate feedback"}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Singafter Mode"})," \u2014 Listen to phrase, then sing it back"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Pitch and rhythm evaluation"}),"\n",(0,s.jsx)(n.li,{children:"Detailed per-phrase scoring"}),"\n",(0,s.jsx)(n.li,{children:"Great for ear training"}),"\n"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-kotlin",children:'val session = CalibraLiveEval.create(lessonMaterial, config)\nsession.onSegmentComplete { result ->\n    println("Segment ${result.segmentIndex}: ${result.score}%")\n}\nsession.start()\n'})}),"\n",(0,s.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.a,{href:"../concepts/pitch-detection",children:"Pitch Detection Concepts"})," \u2014 How pitch detection works"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.a,{href:"../concepts/voice-activity",children:"Voice Activity Concepts"})," \u2014 VAD backends explained"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.a,{href:"../guides/detecting-pitch",children:"Detecting Pitch Guide"})," \u2014 Implementation details"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.a,{href:"../guides/live-evaluation",children:"Live Evaluation Guide"})," \u2014 Building scoring features"]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,l.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},8453(e,n,i){i.d(n,{R:()=>c,x:()=>a});var t=i(6540);const s={},l=t.createContext(s);function c(e){const n=t.useContext(l);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:c(e.components),t.createElement(l.Provider,{value:n},e.children)}}}]);